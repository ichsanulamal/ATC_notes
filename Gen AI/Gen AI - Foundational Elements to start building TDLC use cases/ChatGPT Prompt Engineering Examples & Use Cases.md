# ChatGPT Prompt Engineering Examples & Use Cases

In the spirit of exploring the exciting possibilities of generative AI, this course was built using several AI technologies paired alongside Skillsoft’s trusted design methodologies. Generative AI was used to draft the curriculum plan and on-screen text, while AI text-to-speech services were used for the narration. In addition, generative AI was used to produce the course assessment and AI assistive technologies helped translate the course captions into multiple languages.

Practical prompt engineering is the process of designing refined input prompts to generate responses for natural language processing applications. This involves consideration of prompt factors and various techniques to improve model performance and accuracy.

Through this course, learn about practical prompt engineering and the types of prompts used in ChatGPT. Discover how to write effective prompts for ChatGPT and prompt use in real-world applications. Next, compare prompt types and their uses, explore the ethical considerations of using prompts in ChatGPT, and the impact of prompts on the accuracy of ChatGPT's responses. Finally, examine the relationship between prompts and the training data used to develop ChatGPT.

After course completion, you'll be able to apply prompt engineering practices to develop effective prompts for ChatGPT.

Table of Contents
    1. Video: Course Overview (it_aicpeidj_01_enus_01)

    2. Video: Practical Prompt Engineering (it_aicpeidj_01_enus_02)

    3. Video: Types of Prompts in ChatGPT (it_aicpeidj_01_enus_03)

    4. Video: Effective Prompt Writing for ChatGPT (it_aicpeidj_01_enus_04)

    5. Video: Prompt Assessments in Real-world ChatGPT Apps (it_aicpeidj_01_enus_05)

    6. Video: Ethical Considerations for Using Prompts in ChatGPT (it_aicpeidj_01_enus_06)

    7. Video: The Impact of Prompts on ChatGPT Accuracy (it_aicpeidj_01_enus_07)

    8. Video: Relationship between Prompts and Training Data (it_aicpeidj_01_enus_08)

    9. Video: Building Effective and Relevant Use Cases for ChatGPT Prompts (it_aicpeidj_01_enus_09)

    10. Video: Evaluating the Impact of Different Prompts (it_aicpeidj_01_enus_10)

    11. Video: Identifying Faulty and Problematic Prompt Responses (it_aicpeidj_01_enus_11)

    12. Video: Course Summary (it_aicpeidj_01_enus_13)

    Course File-based Resources

1. Video: Course Overview (it_aicpeidj_01_enus_01)

In this video, we will discover the key concepts covered in this course.

discover the key concepts covered in this course
[Video description begins] Topic title: Course Overview. [Video description ends]
Prompt engineering dives into the world of human - AI interaction and explores the role of prompts to help ChatGPT generate accurate and relevant responses to user queries.

In this course, you'll learn about the concept of practical prompt engineering. You'll explore how to write effective prompts and evaluate their use in real-world applications. In addition, you'll identify prompt types and when to use them.

Next, you'll discuss the ethical considerations of using prompts and the impact that prompts have on response accuracy when interacting with ChatGPT.

Finally, you'll review the relationship between prompts and the training data used to develop ChatGPT, and apply the principles learned to craft prompts for ChatGPT.

2. Video: Practical Prompt Engineering (it_aicpeidj_01_enus_02)

Upon completion of this video, you will be able to outline the concept of practical prompt engineering.

outline the concept of practical prompt engineering
[Video description begins] Topic title: Practical Prompt Engineering. [Video description ends]
When a user interacts with an AI model such as ChatGPT, they do so by means of text inputs known as prompts. Within this context, practical prompt engineering refers to the process of designing and refining the input prompts that are used to generate responses from language models.

This involves crafting prompts or instructions in such a way that the model produces insightful and appropriate responses. By carefully designing the prompts, developers can guide the model to give outputs that are contextually relevant, accurate, and aligned with the intended behavior of the application.

In addition to generating desired output, prompt engineering plays a crucial role in fine-tuning the model to perform well on a specific task or domain. It’s a critical component of many natural language processing applications, including chatbots, virtual assistants, and language translation systems.

During the fine-tuning process, developers provide the data and prompts that align with the fine-tuning task. This involves creating a custom dataset with input-output pairs where the prompt represents the input and the desired response represents the output. The model learns from these examples and adjusts its internal parameters to better generate the expected outputs for similar inputs. In essence, prompt engineering is about designing the inputs and instructions to achieve the desired behavior and train the model effectively for a specific use case.

It's a way to influence the language model's behavior, both during fine-tuning and during its actual usage, when generating responses for users or applications. Crafting high-quality prompts is vital to achieving the desired outcomes and ensuring that the language model performs well in real-world scenarios.

While this course focuses primarily on writing effective prompts to generate suitable content, the principles and best practices discussed apply equally to the process of fine-tuning a model.

Let's start with a discussion of some main types of prompts.

Open-ended prompts allow the language model to generate free-form responses without any specific constraints. This prompt type is useful for tasks such as creative writing, story generation, and generating chatbot responses. Examples of open-ended prompts include: ‘write a story about a magical world’ or ‘describe a perfect day.’

Next are closed prompts. In contrast to open-ended prompts, closed prompts provide specific constraints or guidelines that the language model must follow when generating responses. This can include restricting the response to a certain length or to a specific topic or genre. Some examples of closed prompts are: ‘what is the capital of France’ and ‘what is the answer to 2 + 2?’

Conditional prompts provide additional context or information to the language model which can help it generate more accurate and relevant responses. This might include specifying a particular user persona or demographic, or providing information about the current conversation or topic being discussed. Examples of conditional prompts include: ‘if the user likes action movies, recommend a recent release’ or ‘if the user is feeling sad, generate an uplifting message.’

Finally, there are contextual prompts. This type of prompt uses contextual information to generate a response. For instance, it can be used to output text that is related to a specific topic or situation. Some examples of contextual prompts include: 'write a paragraph about the benefits of exercise' and 'generate a product review for a new smartphone.'

Overall, the type of prompt that is most appropriate will depend on the specific use case and goals of the language model.

The quality of the prompts determines the extent to which the language model can produce the desired output and significantly impacts the user experience. Poorly designed prompts that lack clear guidance and context can cause ChatGPT to output vague, inaccurate, off-topic, or nonsensical responses.

For example, a customer could ask a chatbot for an IT retailer. 'Where can I check out your latest laptops?' If the customer wants to inspect physical products in-store, the chatbot might unhelpfully respond with information on how to add and check out products online. Well-crafted prompts help the model produce more personalized, useful, and engaging responses that consider the user’s preferences, context, and language.

While prompts can be helpful in improving the accuracy and usefulness of language models, there are ethical considerations that should be taken into account when using them.

One ethical concern is bias in prompts, which can impact the accuracy and fairness of the model's responses. If prompts are chosen in a way that reflects existing biases or stereotypes, language models may perpetuate or even amplify these biases in the text they generate. For example, if a language model is given prompts that predominantly feature male characters or use language that marginalizes certain groups, it may generate text that is similarly biased.

Another consideration is the potential for prompts to be used for malicious purposes such as generating text that is abusive, harassing, or manipulative. This could include using prompts to generate fake news or propaganda, or to impersonate someone else online. In such cases, the language model could inadvertently cause harm rather than be a tool for clear communication and understanding.

There is also a question of content ownership and consent when using prompts. Language models often use prompts that are taken from public sources such as online forums or social media posts. While such sources may be publicly available, the individuals who created the content may not have intended for their words to be used by a language model.

In some cases, this could raise ethical issues around privacy and consent. So the use of prompts in language models presents several ethical considerations that must be carefully weighed and addressed.

While prompts can be a powerful tool for improving the accuracy and relevance of language models, their use must be guided by a commitment to fairness, privacy, consent, and the preservation of human communication. Implementing some best practices for practical prompt engineering can help promote the effectiveness and ethical soundness of language models.

Let's consider a few such standard practices. One recommended practice is to ensure that prompts are written in clear and concise language, so that the language model can accurately understand the context of the prompt and generate relevant text.

Another approach is to check for bias and avoid using stereotypical language in prompts, as this may lead to biased language generation. It's essential to use diverse prompts that reflect inclusive and diverse perspectives, cultures, and experiences.

Using relevant examples in your prompts to help the language model understand the context is another good strategy, as it ensures that the AI generates text that is relevant to the task or topic. Providing relevant examples to guide the language model’s response can be an effective way to improve its accuracy too.

It's also a favorable tactic to monitor and evaluate the language model’s performance on a regular basis to identify potential bias and make necessary adjustments to fine-tune the model.

And, always obtain consent for prompt content derived from public sources such as social media or online forums. It's strongly advised to make sure you have permission to use the content from the individuals who created it and that their privacy is protected.

It's recommended to collaborate with experts in the relevant field or domain too, to help ensure that the prompts are accurate, relevant, and free from biases.

By following these best practices, language models can be designed and fine-tuned to generate accurate, relevant, and ethical text that can be used to support various tasks and applications.

3. Video: Types of Prompts in ChatGPT (it_aicpeidj_01_enus_03)

In this video, you will identify the various types of prompts used in ChatGPT.

identify the various types of prompts used in ChatGPT
[Video description begins] Topic title: Types of Prompts in ChatGPT. [Video description ends]
Prompts are an essential part of ChatGPT’s conversational ability. There are various types of prompts that ChatGPT uses to understand and respond to user input. Some are designed to ask questions, while others are meant to provide context or suggest a particular topic.

Prompts serve as the foundation for how ChatGPT interprets and generates responses to user queries. Once you have a stellar understanding of how prompts work, you can communicate with ChatGPT more effectively. There are several reasons why you should know how to use the different types of prompts. Let’s explore some of these.

First, using varied prompt types improves accuracy, which allows ChatGPT to generate better responses. This can result in a more efficient and effective conversation between the user and the AI model.

Second, knowing which prompt type to use can enhance conversational flow, which helps users guide the conversation more naturally. By using prompts that match the conversational context, users can maintain fluidity of language and avoid misunderstandings.

Next, making use of a variety of prompt types allows for increased customization as users can customize their interactions with ChatGPT according to their preferences. This can facilitate a more personalized experience that meets their specific needs.

Last, having a good grasp of the various prompts used in ChatGPT improves learning, helping users to gain an understanding of natural language processing and how AI language models work. It also teaches users how to interact with ChatGPT and similar systems as these technologies change and evolve in the future.

As a language model, ChatGPT is trained to generate responses on different types of input-based prompts. Text prompts are the most common type used with ChatGPT. In this case, the model is given a piece of text as input and generates a response based on that input. For example, a text prompt could be a question like, 'what is the meaning of life?′ Or a statement like, ‘I am feeling sad today.’

Image prompts involve providing an image as input to the model. The model then generates a response based on the image. For example, an image prompt could be a picture of a beach and the model could generate a response like, ‘I wish I could be on that beach right now.’

You can also use video prompts where a video is provided as input to the model. The model then generates a response based on the video. For example, a video prompt could be a clip of a funny cat and the model could generate a response like, ‘that cat is hilarious!’

Finally, there are music prompts where a piece of music is used as input, and the model then generates a response based on the music. For example, a music prompt could be a classical piece, and the model could generate a response like, ‘this music is so soothing.’

To generate responses, the input prompt needs to be properly formatted and passed to the model. The output generated by the model can be presented to the user in a variety of ways, such as text or speech. Overall, using different input-based prompts can help improve the diversity and quality of responses generated by ChatGPT.

And then there are function-based models which are designed to elicit a specific type of response from ChatGPT. Let’s consider some examples of different types of function-based prompts.

Question prompts ask a specific question that the model is expected to answer. For example, a question prompt could be, ‘what is the capital of France?’ The model would then generate a response, such as, ‘the capital of France is Paris.’

Task-based prompts require the model to perform a specific task, such as summarize a text or translate a sentence. For example, a task-based prompt could be, ‘please summarize the main points of this article.’ The model would then return the summary as output.

Free-form prompts allow the user to provide any input they wish, and the model generates a response based on that input. For example, a free-form prompt could be ‘tell me something interesting.’ The model would then generate a response based on its training data and the context of the prompt.

Scenario prompts provide a specific scenario or situation for the model to respond to. For example, a scenario prompt could be, 'you’re lost in the woods, what do you do?′ The model would then generate a response based on the scenario it was given.

Dialogue prompts involve simulating a conversation or dialogue between the user and the model. For example, a dialogue prompt could be, ‘ask me anything.’ The model would then generate a response and continue the conversation based on the user's responses.

Using a variety of function-based prompts can help tailor the model's responses to different needs and perspectives, reduce ambiguity, and improve task execution and efficiency.

Next, we have structured prompts. These are prompts that provide a specific structure or format for the input and output. They can be used to guide a model or user to create specific types of responses without strictly dictating the exact content of those responses.

Some examples of different types of structured prompts are open-ended, fill-in-the-blanks, and multiple choice. Open-ended prompts provide a topic or theme to explore in an open-ended way. For example, an open-ended prompt from a user could be, ‘write a story about a magical creature.’ The model would then generate a story as output.

Fill-in-the-blank prompts provide a sentence or paragraph with one or more missing words or phrases to fill in. For example, a fill-in-the-blank prompt from a bookstore chatbot could be, ‘my favorite author is’ followed by a blank space. The user would then input the author name and the chatbot would return a list of suitable book recommendations.

Finally, multiple choice prompts provide a question or statement with multiple possible responses to choose from. For example, a multiple choice prompt from a model could be, ‘which of these animals is a mammal? (a) Bird (b) Fish (c) Dog or (d) Insect.’ The user would then choose one of the options, and the model would generate a response based on that choice.

Using a diverse selection of structured prompts can help ChatGPT to generate responses that are tailored to specific formats and types of input.

There are best practices to follow for choosing the right type of prompt. First, understand the audience. The type of prompt you choose could be based on the audience you're interacting with. For example, closed prompts might be better for people who are less familiar with the topic. While open-ended prompts might be better for experts.

Next, determine the purpose of the prompt. Ask yourself what you want to achieve with the prompt. Is it to provide information, generate ideas, or engage in conversation? The purpose of the prompt influences the type of prompt that is most appropriate.

Third, consider the desired level of creativity or accuracy. If you want ChatGPT to provide more creative responses, then open-ended prompts might be the best choice. In contrast, if you'd like ChatGPT to provide factual information, then closed prompts might be more appropriate.

Next, understand the context. The context of the conversation or situation can impact the type of prompt that is most effective. For example, contextual prompts might be necessary if the conversation involves multiple topics or is ongoing.

Finally, test and iterate. It's important to assess distinct types of prompts and evaluate their effectiveness. This can help you refine your approach and choose the best type of prompt for a specific situation.

Choosing the right prompt type is critical for achieving the desired outcome when working with ChatGPT. By understanding the audience, purpose, desired level of creativity or accuracy, context, and testing several types of prompts, you can select the most appropriate prompt and improve the overall quality of the conversation.

4. Video: Effective Prompt Writing for ChatGPT (it_aicpeidj_01_enus_04)

In this video, recognize how to write effective prompts for ChatGPT.

recognize how to write effective prompts for ChatGPT
[Video description begins] Topic title: Effective Prompt Writing for ChatGPT. [Video description ends]
When it comes to writing effective prompts, one important factor to consider is the length of the prompt. Prompts should be short and to the point, as this helps ensure that the language model understands exactly what is being asked.

At the same time, it's also essential that a prompt includes all the necessary information. For example, if the goal is to write a convincing essay about the benefits of exercise, the prompt should clearly specify the type of essay required - ‘argumentative,’ and the topic - ‘benefits of exercise.’

A well-crafted prompt provides enough detail to guide ChatGPT in the right direction, while still allowing for creativity and originality in the responses. Another important aspect of writing effective prompts is providing context to help ChatGPT understand what you're looking for.

For example, if you ask the language model to write a descriptive essay about a city, providing context such as the city’s location, cultural significance, and notable landmarks can help ChatGPT better understand what type of description is required.

Additionally, including specific details about the task or question at hand, can guide the response. For example, supplying specific details about the purpose and audience, can help ChatGPT provide even more targeted and relevant responses.

By providing context and specific details, you can ensure that ChatGPT understands exactly what's expected and can respond accordingly. Using examples can be a powerful tool when writing effective prompts for ChatGPT. You can use examples to clarify what information you want and provide a clearer picture of what you expect in the response.

For example, to write a persuasive essay on the topic of animal rights, you can include specific examples of issues or arguments to help ChatGPT better understand the task and provide more focused responses.

When providing examples, ensure that they're specific and directly related to the task or question at hand. For example, when creating a descriptive paragraph about a person, including specific examples of physical features, personality traits, or actions, can help ChatGPT better understand what type of description is required.

5. Video: Prompt Assessments in Real-world ChatGPT Apps (it_aicpeidj_01_enus_05)

After completing this video, you will be able to outline the use of prompts in real-world applications.

outline the use of prompts in real-world applications
[Video description begins] Topic title: Prompt Assessments in Real-world ChatGPT Apps. [Video description ends]
Real-world applications of AI, such as customer service chatbots and virtual assistants, require ChatGPT to understand a user's intent and generate accurate responses quickly and efficiently.

ChatGPT has been pre-trained on vast amounts of text data sourced from parts of the Internet, which helps it understand language structure, common phrases, and general knowledge. However, readying the model to perform effectively in a particular setting requires an additional fine-tuning process using a custom dataset.

This dataset serves as the training material that the model uses to adapt its behavior to a specific task, domain, or style of conversation. It’s comprised of input-output pairs, where the prompt represents the input, and the desired response represents the output.

For customer service applications such as chatbots, the input prompts should be designed to anticipate the types of questions that customers are likely to ask; and provide clear and concise answers as the outputs. By keeping prompts short and to the point, chatbots can quickly provide customers with the information they need.

For example, a prompt such as, ‘what is your return policy,’ can be answered with a short reply that provides the necessary information. 'Our return policy allows for returns within 30 days of purchases with a valid receipt.′ Prompts can also be used to guide customers through specific processes, such as placing an order or troubleshooting an issue.

By providing clear and specific prompts during the fine-tuning phase, chatbots can help customers successfully navigate these processes step-by-step. In chatbot development, prompts are typically based on the data collected from previous interactions between the chatbot and users. During fine-tuning, this data helps the chatbot understand the patterns in user queries and responses, and the specific language that users typically use in each situation.

Prompts are also used to train chatbots to recognize and understand different types of questions. For example, prompts can teach chatbots to recognize the intent behind a user's question, such as a request for information, a complaint, or a request for help. Prompting can also be used to teach chatbots to recognize and respond appropriately to different contexts based on the use of industry specific terminology, technical jargon, or informal language.

When it comes to evaluating the performance of ChatGPT and other language models, prompts also play a significant role. By providing a set of standardized prompts that covers a range of topics and situations, you can assess the accuracy and relevance of the language model’s responses.

Prompts can be designed to test a model's ability to comprehend the terminology, jargon, or technical language used in various industries. This helps evaluate the model's ability to respond in specific contexts.

Developers can also use prompts to pinpoint whether the language model may create inaccurate or inappropriate output. Analyzing a model's responses to prompts can help reveal error patterns and areas where the model may require further fine-tuning.

By providing a standardized and consistent framework for testing and evaluating a model's responses, prompts can help identify strengths and weaknesses in the model's performance.

There are several best practices to help you craft prompts that are effective at producing useful results from ChatGPT in real-world applications.

First, be consistent with your use of terminology and language in your prompts. Consistency helps ChatGPT learn and recognize patterns, resulting in more accurate and relevant outputs over time.

Second, continuously update the prompts. ChatGPT may face different questions and scenarios over time, so it's crucial to update and refine the training prompts to reflect these changes.

Third, provide feedback to ChatGPT on its responses to your prompts, to help with long term evolution and improvement of the model. This can be done via the user interface to rate responses, flag problematic outputs, or leave detailed comments. Feedback can also be provided directly to OpenAI support.

Ultimately, prompts determine the value that language models can offer across a wide range of real-world environments. When used effectively, prompting prepares the model to respond precisely and intelligently, to questions and scenarios, in any given context.

6. Video: Ethical Considerations for Using Prompts in ChatGPT (it_aicpeidj_01_enus_06)

After completing this video, you will be able to outline the use of prompts in real-world applications.

identify the ethical considerations surrounding the use of prompts in ChatGPT
[Video description begins] Topic title: Ethical Considerations for Using Prompts in ChatGPT. [Video description ends]
In the practical prompt engineering video, earlier in this course, we touched on some of the ethical concerns when using prompts in language models. Here we'll go into more detail on the role of ethics as a critical factor in prompt engineering.

First, prompts that are unreliable have the power to negatively impact people's lives. ChatGPT has the potential to provide information and advice, so it's vital that it produces accurate responses, responsibly. For example, a prompt that elicits information on an investment strategy that promises to double your money in one month could be misleading and result in serious financial losses.

Second, prompts that contain unauthorized use of sensitive information can lead to legal issues or trust breaches. ChatGPT should not be allowed to handle sensitive information such as personal data and confidential details without authorization. Such information must be protected and may not be misused.

Prompts that are designed to influence or manipulate can have severe repercussions on individuals and broader society. So it's crucial to consider the implications in areas such as politics and advertising. For example, a prompt could be used to generate misinformation to discredit a political opponent.

And last, the use of prompts in ChatGPT can cause bias and discrimination. This can occur due to the biased data or models leading to the propagation of stereotypes and inequality. For example, a dataset used to fine-tune a model could promote cultural bias if it equates beauty with lighter skin tone or western features.

Making ethical considerations the priority when developing prompts is key to ensuring that the technology is used safely and responsibly. It's essential to consider the potential consequences of prompts and take proactive measures to mitigate any harm. One way to ensure that the responses generated by ChatGPT are ethical is through the language and information you use in your prompts. You must ensure the language used is responsible and accurate. Vague or imprecise prompts can lead to incorrect or harmful responses.

Prompts should be reviewed by subject matter experts for appropriateness and accuracy. For example, due to the lack of a specific time frame or urgency level, a prompt seeking advice on how to lose weight fast could return a recommendation of extreme dieting practices that potentially jeopardize a person's health. Prompts should never contain biased or discriminatory information.

Instead, use inclusive language that avoids perpetuating stereotypes, prejudices, or any particular viewpoint or agenda. Ensure your sources are trustworthy and that the information in your prompts is factually accurate and supported by evidence.

Finally, be aware of inappropriate language or the use of sensitive information in prompts to avoid potential legal, reputational, or societal consequences. Especially in spheres such as politics and advertising, the use of prompts to influence people's perceptions, beliefs, and behaviors can be a real concern. So to do your part, make sure that prompts do not spread false information.

In politics and in advertising, especially, unethical use of prompts could lead to the manipulation of public opinion and even influence election outcomes. For example, if a political campaign uses ChatGPT to generate biased or misleading information through prompts, it could have a significant impact on voters' perceptions and decisions.

Ensure that prompts do not manipulate individuals. In advertising, unethical use of prompts could result in responses that are false or make misleading claims about products or services. For example, if a company prompts ChatGPT to generate responses that falsely claim benefits of a product, this could lead to consumers making purchasing decisions based on inaccurate information. It's therefore essential for prompts and those used within the context of politics and advertising, in particular, to be designed and deployed in an ethical and responsible manner, with appropriate safeguards in place.

At a minimum, language must be clear and factual, and information should be free from bias, prejudice, or discrimination. The use of sensitive information in ChatGPT prompts comes with significant ethical considerations and responsibilities. So organizations must implement strict security measures and data protection policies to safeguard any sensitive information that ChatGPT users may handle.

If a privacy breach were to occur in ChatGPT, this can have a number of detrimental consequences. Companies or individuals responsible for the breach could face legal action and hefty financial penalties for violating privacy laws. Breaches may result in a loss of trust, reduced revenue, and reputational damage for all parties involved.

Sensitive information could be used by cybercriminals to steal someone's identity, access their financial accounts, or commit other forms of fraud. If classified data is accessed or used improperly, it could result in discrimination or bias against certain individuals or groups. For example, if a company’s discriminatory hiring patterns are breached via ChatGPT, and subsequently accessed by others, the compromised data could be misused to perpetuate similar biases in other hiring scenarios. Privacy breaches that become public can also create a significant negative backlash from the media, public, and advocacy groups.

When using ChatGPT, privacy must therefore be protected at all costs, and information kept secure. This includes ensuring that any sensitive information is not shared through prompts or used for malicious purposes. Through the implementation of appropriate security measures such as encryption and access controls, organizations can prevent unauthorized access to information. Additionally, it's crucial to establish clear policies and guidelines around the use of ChatGPT prompts and ensure all users are aware of these policies and the consequences of violating them.

AI use policies should also be regularly reviewed and updated to ensure they remain effective and up to date with changing technologies and threats. By taking these steps, you and your organization can help ensure that ChatGPT is used responsibly and for the benefit of society, while also protecting the privacy and security of an individual’s sensitive information.

Regular review and evaluation of prompts are essential to identify potential ethical issues and ensure that the prompts align with ethical principles and standards. It's recommended that organizations establish and implement a process for reviewing and evaluating prompts before they are used in ChatGPT. This process should involve a team of experts who can identify potential ethical issues and suggest ways to mitigate or avoid them.

During the review process, various factors should be considered, such as the language used in the prompts, the information being passed on, and the potential impact on individuals or society. This review process should also take feedback from users and stakeholders who may have concerns about the prompts, or their use, into account.

And to maintain alignment with ethical principles and standards, prompts should regularly be evaluated through user testing, feedback collection, and impact analysis. Any issues that arise during such an evaluation should be addressed timeously, so prompts continue to be used in a responsible and ethical manner.

Maintaining transparency around the use of prompts, and the information collected by ChatGPT, is also key for ensuring that ethical considerations are being met. One way to increase transparency is by providing clear information about the purpose of prompts and how any information that's collected will be used. This can be done through a privacy policy or terms of use document that is easily accessible to users.

Another essential measure for establishing transparency is being open about the limitations of ChatGPT and the prompts it can produce. ChatGPT is still an AI system and can have limitations in its ability to provide accurate or complete information. By being transparent about these limitations, users can make better decisions about how they use the information they receive from ChatGPT.

It's also pertinent to allow users to have control over how their information is used. This can be done by providing options to opt-out of data collection or delete personal information upon request. Providing users with this level of control can help ensure that ethical considerations around privacy are met.

Regular communication with users about updates to the system and any changes in the use of prompts can further promote transparency. This might include notifications about updates to the privacy policy or changes in how data is collected and used, for example.

Several measures can and should be taken to prevent ethical infringements. First, consult ethical guidelines for a prompt development framework that aligns with ethical principles. For instance, the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems provides a set of principles for designing AI systems that are transparent, accountable, and unbiased.

Second, use diverse input sources for prompts to prevent bias. For instance, if you're developing a prompt for medical advice using input sources from a diverse set of medical professionals can help minimize the risk of biased information.

Next, test prompts for potential biases before they are deployed. This can be achieved through a process of validation, where multiple users with different backgrounds, interact with the prompts and provide you with their feedback.

Finally, incorporate transparency and accountability in the design of prompts. This means users should have a clear understanding of how the prompts work and how their information may be used. Additionally, there should be mechanisms in place to hold developers and users accountable for any unethical use of prompts.

By following these measures, developers and users of ChatGPT can ensure that prompts align with ethical principles and standards, thereby minimizing potential negative consequences and maximizing the technology's benefits for society.

7. Video: The Impact of Prompts on ChatGPT Accuracy (it_aicpeidj_01_enus_07)

Upon completion of this video, you will be able to recognize the impact of prompts on the accuracy of ChatGPT's responses.

recognize the impact of prompts on the accuracy of ChatGPT's responses
[Video description begins] Topic title: The Impact of Prompts on ChatGPT Accuracy. [Video description ends]
When interacting with ChatGPT, accuracy refers to the model's ability to generate responses that are relevant, informative, and grammatically correct based on the input it receives from a user. Organizations and developers can measure model accuracy by comparing the model's output to a human-generated response or to a set of pre-defined correct responses.

For example, if a user asks ‘what is the capital of France’ and ChatGPT responds with ‘Paris,’ then the model is said to have achieved a high level of accuracy for that particular input. Even after fine-tuning a model for a specific use case, it’s important to continue evaluating and improving the model’s accuracy over time, to ensure it provides the best possible user experience.

To explore this further, let's review the two key factors that influence the accuracy of ChatGPT's responses.

The complexity and quality of prompts can greatly affect accuracy. For example, if a prompt is vague or contains irrelevant information, the model may generate responses that are off-topic or unhelpful. In contrast, if a prompt is well-defined and focused, the model is more likely to respond with accurate and applicable information.

Another factor that directly influences the accuracy of responses is the quantity and quality of the training data used to develop a model. In general, a model that's been trained on a large and diverse dataset will be better equipped to handle a broad range of prompts and generate accurate responses. This applies to both the size and quality of the training data used to pre-train ChatGPT and the custom datasets used to fine-tune a model for a specific real-world application.

Let's dig deeper into some of the key characteristics of a good prompt. Prompts should be clear and well-defined with a specific question or request. They should also have sufficient context. This may include information about the topic, the user's preferences, or the current conversation.

In addition, prompts should be concise, to the point, and relevant to the intended topic, question, or request. This helps to avoid confusion and ensures the model focuses on the most important aspects of the user’s instruction.

To demonstrate, here are some examples of well-defined and focused prompts.

‘What is the best time of year to go skiing in Switzerland?’ This prompt is clear, well-defined, and contextual; providing information about the location and request. It's also applicable to the intended topic.

‘What are the best ways to reduce stress and anxiety?’ This prompt is contextual, providing information about the user's specific concern.

‘How do I set up a new Gmail account on my iPhone using the Mail app?’ This prompt is clear, well-defined, and provides the specific context and details for the question by including the email provider and the smartphone make, along with the app used. This additional information helps ChatGPT generate a more targeted and useful response.

Let’s now consider some examples of vague and ill-defined prompts.

‘What do you think about life?’ This prompt is too broad and ambiguous, making it difficult for ChatGPT to identify what information a user may want.

'Can you give me some tips for being successful?′ This prompt is vague and lacks sufficient context, making it challenging for ChatGPT to interpret the user's specific concerns correctly and provide helpful advice.

‘How long does it take to get to Florida?’ Again, this prompt is too vague and lacks context. Without additional information about the user’s current location and mode of transport, it’s almost impossible for ChatGPT to provide a suitable response. As you can tell, poorly-designed prompts that are vague, irrelevant, or lack context can create challenges for ChatGPT to generate accurate and helpful responses.

Let's also take a moment to highlight the challenges that can arise from using poorly-designed prompts.

A vague prompt can cause ChatGPT to misunderstand the user's intent, leading to irrelevant or inaccurate responses. For example, a prompt like ‘What’s up’ can be interpreted in many ways, increasing the likelihood of an errant response.

A prompt that doesn't relate to the intended topic or request can result in ChatGPT generating unhelpful responses. For instance, asking ChatGPT about the managing partners at a law firm, when the law firm name bears similarity to a fictional law firm in a television show. The model may respond with details about the TV show, which diverges from the user's question.

An ambiguous or poorly-phrased prompt can cause ChatGPT to generate inaccurate or misleading responses. For example, a prompt like ‘tell me about cars’ is ambiguous and can lead to responses that are too broad or vague.

And finally, a prompt that's too complex or contains multiple questions can confuse the model. For instance, a prompt such as 'can you tell me the best places to eat in this city and what tourist activities it has to offer,′ contains multiple questions without context, meaning ChatGPT is likely to respond inaccurately.

8. Video: Relationship between Prompts and Training Data (it_aicpeidj_01_enus_08)

In this video, compare the relationship between prompts and the training data used to develop ChatGPT.

compare the relationship between prompts and the training data used to develop ChatGPT
[Video description begins] Topic title: Relationship between Prompts and Training Data. [Video description ends]
Previously, we discussed how ChatGPT responses depend on the quality and accuracy of the prompts. Now we'll examine how the quality of the training data provided to the model also affects the quality of ChatGPT’s responses. This includes both the large dataset used to pre-train ChatGPT, as well as the custom dataset used to fine-tune it.

During the pre-training and fine-tuning processes, developers use training data to teach ChatGPT the patterns and relationships between language and context through a process called supervised learning.

For example, in the case of language generation, the AI model is trained on pairs of text inputs and outputs. By analyzing these pairs of inputs and outputs, ChatGPT learns the relationships between words, phrases, and sentences; and how to generate responses based on the context provided by the input prompt.

Because training is an iterative process, the model is exposed to the training data multiple times and adjusts its internal parameters based on the patterns it observes in the data. The more data ChatGPT is trained on, the better it becomes at generating accurate responses.

If large training data sets contain diverse and inclusive examples, this helps to improve the model's performance. For example, a large dataset that includes a variety of conversational styles and topics, can help ChatGPT generate more versatile responses for a wide range of user queries. Additionally, large datasets help to reduce the impact of bias and noise in the training data, as the model learns from more extensive and diverse examples.

The GPT-3 language model, for instance, was pre-trained on a large dataset of over 570GB of text data. This is significantly larger than the training data used for previous GPT models. The latest release, GPT-4, has an even larger context window, which acts as the model's short-term memory.

The context window determines how much past information the model can refer to, when generating responses. This increased capacity allows more input while ensuring greater response accuracy, detail, and creativity.

While ChatGPT’s pre-training is performed by its developers, OpenAI, custom datasets can be used during the fine-tuning phase to prepare the model for specific real-world applications. The quality of this fine-tuning data is critical in determining the model's proficiency within its intended environment.

High-quality data is defined as data that accurately represents the types of questions and situations that the model may encounter in practice. So when fine-tuning, organizations should ensure the training data used is diverse, comprehensive, and representative of a wide range of contexts and situations.

Diversity in the data means the dataset includes examples from a variety of topics and domains, which helps the model to generalize to new and unseen examples, and generate increasingly diverse and relevant responses. For example, fine-tuning ChatGPT on a dataset that includes references to various cultures and languages, helps ChatGPT to produce more culturally-sensitive and diverse results.

The relevancy of the data is equally important. When fine-tuning, it's pertinent to include data that's directly related to the intended application, as this helps improve the model's accuracy. For instance, if ChatGPT is fine-tuned on a dataset that focuses on sports, it may not be able to generate accurate replies to queries about medical topics or other subjects unrelated to the sports data it was trained on.

Exposing ChatGPT to high-quality data increases the model's ability to learn from examples and generate suitable results. In contrast, poor-quality data can introduce noise and errors, leading to flawed responses. For instance, if training data contains spelling or grammatical errors, ChatGPT may learn to generate content with similar mistakes.

Poor-quality data that’s incomplete, biased, or limited can lead to the model making incorrect assumptions or not recognizing certain patterns or trends at all. So the relationship between prompts and training data is a two-way street. Poor-quality training data produces poor responses to prompts, no matter how well-crafted the prompts may be. And poor-quality prompts used in training, can retrieve irrelevant or unsuitable data, regardless of how accurate the training data may be.

In essence, when fine-tuning, the prompts and the desired responses work in tandem. The prompts guide the model’s attention acting as a lens or focus mechanism, while the responses teach the model what kind of output is expected for the prompts that it’s given.

Therefore, to ensure that ChatGPT generates accurate and relevant responses, it's essential to carefully choose the prompts and training data during fine-tuning, to ensure they are high-quality and relevant to the types of questions and situations that the model is expected to encounter in real-world settings.

There are some steps you can take to craft effective prompts while fine-tuning a model. First, identify the target audience. If the target audience is healthcare professionals, for example, the prompt should focus on medical terminology and healthcare scenarios.

Second, use real-world examples to provide context and help the model learn the relationships between language and context. Third, employ a variety of prompts that cover a broad range of topics and situations. This helps the model learn to handle diverse types of inputs and recognize relevant patterns and relationships for generating accurate responses.

Next, avoid biased or leading prompts that can result in inaccurate or inappropriate responses. And last, continuously update the prompts. ChatGPT may face increasingly evolving questions and scenarios over time, so it’s crucial to update and fine-tune the prompts to reflect these changes.

Next, let's explore some examples of diverse and relevant datasets that could be used to fine-tune a model. An inclusive and diverse training dataset could include news articles from a broad range of sources, covering an array of topics such as politics, sports, arts, and entertainment. The dataset could contain customer support chat logs, which can provide diverse examples of actual customer inquiries and responses from support agents related to the sales experience.

Another form of training data could be movie reviews, which provide both positive and negative opinions and perspectives on movies from various genres and time periods.

Lastly, scientific research papers could be another valuable source of data that covers a broad scope of fields such as biology, chemistry, and physics. By using diverse and relevant training data, developers can improve ChatGPT’s accuracy and ensure that the model is able to generate useful responses across an assortment of topics and domains.

9. Video: Building Effective and Relevant Use Cases for ChatGPT Prompts (it_aicpeidj_01_enus_09)

In this video, find out how to build solid use cases to create effective and relevant ChatGPT prompts.

build solid use cases to create effective and relevant ChatGPT prompts
[Video description begins] Topic title: Building Effective and Relevant Use Cases for ChatGPT Prompts. [Video description ends]
Building solid use cases is a key step in creating effective and relevant ChatGPT prompts. Let's now explore this further by means of a demonstration. To get started, open a web browser on your computer or mobile device and navigate to chat.openai.com

Once you're there, sign in to your OpenAI account or create a new one if you don't have one. [Video description begins] The Welcome to ChatGPT page is open on the browser. It has two options - Log in and Sign up. [Video description ends] For the purposes of this demonstration, you already have an account that uses the paid subscription service of ChatGPT. There's also a free service with some limitations. Notably, you may not be able to access ChatGPT during busy times.

For this demonstration, the use case involves using ChatGPT to generate creative product descriptions for a fictional online store selling eco-friendly products. This scenario is practical, demonstrable, and relevant as it showcases the potential of AI in enhancing creativity and productivity. [Video description begins] The browser has switched to the home screen of ChatGPT PLUS, with GPT-4 selected in the Model drop-down at the top and a prompt box at the bottom. [Video description ends]

First, let’s define the goals and objectives of the use case. For the eco-friendly online store, the goal is to create engaging and informative product descriptions that highlight the environmental benefits and features of the products. This helps attract customers and encourages them to make a purchase. Next, you can craft prompts that address the objectives of the use case. To illustrate the importance of prompt engineering, this demonstration provides three examples. A poor prompt, a mediocre prompt, and a good prompt which get typed at the bottom of the screen in the prompt box.

The first one is a poor prompt - ‘write about a bag.’ [Video description begins] The presenter inserts the prompt in the prompt box, and ChatGPT starts to return a text-based output almost instantly. An option to Stop generating becomes visible right above the prompt box. [Video description ends] This prompt provides no context or direction about what to do with it. Establishing a clear and distinct context for your inputs is key to successful prompt engineering.

[Video description begins] The host clicks on the Stop generating button and the output stops midway. The Stop generating button now turns into a Regenerate response button. The output is a vague, fantasical tale that reads more like a story instead of a product description. [Video description ends] This prompt leaves ChatGPT to either ask for more detail or make up something whimsical. Although this can be fun and entertaining, prompts like this one aren't very useful.

The second one is a mediocre prompt. ‘Write a description for a reusable food storage bag.’ [Video description begins] The presenter now inserts the second prompt in the prompt box, and the same process repeats. [Video description ends] Unlike the poor prompt, the mediocre one gives ChatGPT a little more detail, but you'll notice that it's also lacking any meaningful context. So while you have added the three modifiers: reusable, food, and storage, ChatGPT still doesn’t have any direction from the prompt and proceeds like with the poor prompt in a whimsical and entertaining direction.

And the last one is a good prompt. 'Write a creative product description for a reusable silicone food storage bag that emphasizes its eco-friendly features and benefits for the user.′ [Video description begins] The presenter inserts the third prompt in the prompt box. [Video description ends] By now, you should be able to pick out what is meant by context and the difference between it and modification. The modifiers here should be easy to pick out. Reusable, silicone, food, and storage.

But now, in very short order, you have a wealth of contexts like creative product description, emphasizing eco-friendly, and of course, features and benefits. The latter signals to ChatGPT that this is probably a marketing response.

To review, by crafting clear and specific prompts, you can guide ChatGPT to generate the desired output. A good prompt is clear, has purpose, and most importantly, as discussed in previous courses, has a well-defined context. By being clear, purposeful, and providing context, the good prompt helps guide ChatGPT to generate relevant and effective content that meets the goals and objectives of the use case.

This demonstrates the importance of prompt engineering and how careful crafting of prompts can significantly impact the results you achieve from ChatGPT.

Once you have the generated content, you'll assess the effectiveness of the output. This involves evaluating the quality, relevance, and creativity of the AI-generated product descriptions. It's crucial to ensure the descriptions meet your goals and objectives while remaining engaging and informative.

Lastly, you'll iterate and refine your prompts based on the initial results. This may involve rephrasing the prompts or providing additional context to improve the generated content. Remember, prompt engineering is an iterative process and refining your prompts can significantly impact the results you receive from ChatGPT.

For example, you can refine a prompt by including additional aspects. Here's an example of an iterative prompt that incorporates missing elements. Let's add the following prompt to the prompt box. 'Write a creative product description for a reusable silicone food storage bag that emphasizes its eco-friendly features, durability, and ease of cleaning for the user.'

Iteration means experimenting over and over again with the prompt. Some people might call this "tweaking" the prompt. Have fun and be creative with the prompt. Ask ChatGPT to respond from the customer's point of view. Experiment with different types of modifiers. Ask ChatGPT to give 2 or 3 versions of the iterative responses and then ask it to compare and contrast them. By refining the prompt in this way, you increase the likelihood of generating a product description that better meets your intended application.

10. Video: Evaluating the Impact of Different Prompts (it_aicpeidj_01_enus_10)

In this video, we will evaluate the impact of different prompts on ChatGPT's output by experimenting with various prompts to create engaging product descriptions.

evaluate the impact of different prompts on ChatGPT's output by experimenting with various prompts to create engaging product descriptions
[Video description begins] Topic title: Evaluating the Impact of Different Prompts. [Video description ends]
In this demonstration, the focus is on evaluating the impact of different prompts on ChatGPT’s output. Using the context of a fictional online store selling eco-friendly products, you can experiment with various prompts to create engaging product descriptions.

To get started, open a web browser on your computer or mobile device and navigate to chat.openai.com [Video description begins] The Welcome to ChatGPT page is open on the browser. It has two options - Log in and Sign up. [Video description ends] Once there, sign in to your OpenAI account or create a new one if you don’t have one.

or the purpose of this demonstration, let’s start by iterating through three different prompts for the same product, a reusable silicone food storage bag. [Video description begins] The browser has switched to the home screen of ChatGPT PLUS, with GPT-4 selected in the Model drop-down at the top and a prompt box at the bottom. [Video description ends] To observe how subtle changes can impact the results generated by ChatGPT, in this demonstration you’ll give each prompt a different focus.

Note that each prompt gets added in the prompt box located at the bottom of the screen. The first prompt is 'write a creative product description for a reusable silicone food storage bag, emphasizing its eco-friendly features.′ [Video description begins] The presenter inserts the first prompt in the prompt box. [Video description ends]

Since its focus is on eco-friendly features, the result is a product description emphasizing the environmental benefits of the reusable silicone food storage bag, such as reducing plastic waste and conserving resources.

For the second prompt, you input 'write a product description for a reusable silicone food storage bag focusing on its practical and user-friendly design.′ [Video description begins] The presenter now inserts the second prompt in the prompt box. [Video description ends]

In this case, the practical and user-friendly design is highlighted, generating a description that discusses the ease of use, cleaning, and storage of the bag, thereby appealing to customers who value convenience.

Finally, the third prompt is 'describe a reusable silicone food storage bag in a way that highlights its durability and long-term cost savings.′ [Video description begins] The third prompt is inserted in the prompt box. [Video description ends]

By concentrating on durability and long-term cost savings, this prompt produces a description that underscores the bag’s robust construction, its ability to withstand wear and tear, and the potential savings from not having to purchase single-use plastics.

Experimenting with different prompts in this way shows how ChatGPT is able to generate content based on the specific focus and context provided. By changing the focus of the prompts, this leads to distinct descriptions that emphasize different aspects of the product. This demonstrates the importance of tailoring prompts to address specific objectives and desired outcomes.

Lastly, you can refine your prompts based on the insights gained from your evaluation. For instance, let's focus on the results from this first prompt, which focused on the eco-friendly features of the reusable silicone food storage bag. If you find that the description generated does not adequately convey the environmental benefits, you could rephrase the prompt to be more explicit.

Let's add the following prompt in the prompt box. 'Write a creative product description for a reusable silicone food storage bag that highlights its positive impact on reducing plastic waste, conserving resources, and contributing to a greener planet.' Note how the increased level of specificity has contributed to a richer and more detailed output.

This is the power of context, modification, and iteration coming together in one prompt. And especially if you’re new at prompt engineering, this can only be achieved through experimentation. By making adjustments like this, you can better align the prompts with your objectives and further improve the quality and relevance of the AI-generated content.

11. Video: Identifying Faulty and Problematic Prompt Responses (it_aicpeidj_01_enus_11)

In this video, we will evaluate the impact of different prompts on ChatGPT's output by experimenting with various prompts to create engaging product descriptions.

identify faulty and problematic prompt responses in ChatGPT, as well as potential issues that may arise from poorly crafted prompts
[Video description begins] Topic title: Identifying Faulty and Problematic Prompt Responses. [Video description ends]
In this demonstration, the focus is on identifying faulty and problematic prompt responses in ChatGPT. By understanding the potential issues that may arise from poorly-crafted prompts, you’ll learn how to create more effective prompts that generate the results you're seeking.

To get started, open a web browser on your computer or mobile device and navigate to chat.openai.com [Video description begins] The Welcome to ChatGPT page is open on the browser. It has two options - Log in and Sign up. [Video description ends] Once there, sign in to your OpenAI account or create a new one if you don't have one.

For the purposes of this demonstration, let's examine an ambiguous prompt that results in an unclear response. [Video description begins] The browser has switched to the home screen of ChatGPT PLUS, with GPT-4 selected in the Model drop-down at the top and a prompt box at the bottom. [Video description ends] Note that the prompts must be added to the prompt box located at the bottom of the screen.

Suppose you want ChatGPT to provide a recommendation for the best way to conserve energy at home. The initial prompt might be ‘what’s the best thing to do?’ This prompt is too vague and doesn't specify the context leading ChatGPT to ask for more specific information about the request.

In this demonstration, a second example involves an inappropriate or biased prompt that leads to a biased response. So you’ll ask ChatGPT ‘why are people who drive gas-powered cars selfish?’ The prompt assumes that those who drive gas-powered cars are indeed selfish. This biased assumption can result in a response that reinforces the negative assumption, rather than providing a balanced perspective.

Now, let's identify the issues with these two problematic prompts. In the first example, the problem is a lack of context and specificity, which leads to an unclear response. In the second example, the issue is the biased assumption embedded in the prompt, which may reinforce or perpetuate stereotypes or misinformation.

To address these issues, you can employ techniques such as rephrasing the prompts to be more specific and neutral. For example, you can modify the first prompt to ‘what’s the best way to conserve energy at home?’ And then refine the second prompt to ‘what are the environmental differences between driving gas-powered cars and electric vehicles?’

By refining your prompts, you can generate more accurate and useful responses from ChatGPT.

12. Video: Course Summary (it_aicpeidj_01_enus_13)

In this video, we will summarize the concepts covered in this course.

summarize the concepts covered in this course
[Video description begins] Topic title: Course Summary. [Video description ends]
In this course, you explored the concept of practical prompt engineering in more detail, which is the process of designing prompts that enable ChatGPT to understand and generate accurate and relevant responses to user queries.

Prompt engineering is a critical component of the fine-tuning process that can significantly affect the accuracy and relevance of an AI model’s responses.

You explored a variety of different types of prompts used, such as question prompts, context prompts, and open-ended prompts. Each type serves a different purpose and provides ChatGPT with the information required to produce useful responses.

In addition, you discovered that writing effective prompts requires an understanding of the intended application and the types of questions and situations the model may encounter in real-world settings. Effective prompts should be diverse, relevant, and representative of the context within which they will be used.

Next, you reviewed the ethical implications of using prompts in ChatGPT. The way prompts are designed can inadvertently introduce bias into the responses. Therefore, prompt engineers need to be vigilant in designing prompts that are fair, unbiased, and representative of a wide range of perspectives.

Another factor to consider is the impact of prompts on the accuracy of ChatGPT’s output. Poorly-designed prompts can lead to inaccurate and irrelevant responses which can negatively impact the user experience. Conversely, well-designed prompts can help the model produce accurate and applicable responses that better meet user needs.

Finally, you explored the two-way relationship between prompts and training data. The quality of both the training data and the prompts used to train ChatGPT affect the accuracy and relevance of its responses to prompts. Therefore, when fine-tuning a model, developers need to use diverse and representative data in combination with well-crafted prompts to improve the model's behavior and performance in its intended environment.

You'll explore more advanced ChatGPT prompting strategies in the next course.

Course File-based Resources
•	ChatGPT Prompt Engineering Examples & Use Cases
Topic Asset
© 2024 Skillsoft Ireland Limited - All rights reserved.