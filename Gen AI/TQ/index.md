Welcome to TQ Gen AI
TQ Generative AI (Gen AI): Opening
Hey, everyone. You're probably wondering why we're rolling out a thirteenth TQ topic on generative artificial intelligence when we recently updated our existing AI topic and we rolled out some other videos in 2023. And the short answer is that generative AI is that important to the future of our business. It's big. Our CEO, Julie Sweet, recognized this new landscape when she called for us to equip all of our Accenture employees on generative AI foundations. And that's what this TQ topic is primarily about and the way that will equip all of you to do this. The field is changing so rapidly and the impact of this technology is so large that we want to cover generative AI in a longer, more comprehensive way and have a little fun along the way. While AI has been a fundamental part of our technological landscape for decades, generative AI represents a substantial leap forward, revolutionizing the way that we work, learn, and interact with technology and with one another. The inflection point that I told you was coming in the earlier module has now happened. We're caught up in the incredible unfolding of AI technology, which is very exciting. And my job as a chief technology and innovation officer is to prepare you for what's to come. Generative AI is going to drive the reinvention of business. I've said it before, AI is going to impact every single aspect of business. It's people, processes, systems, and applications. It's already leading to new forms of customer engagement and new business models and taking human productivity to the next level of potential. That's why we founded the Center for Advanced AI. And going even further, it's why we're launching new GenAI studios. These studios will give our people a place to learn and advance their skills, co innovate with clients, and conduct pilots. As you go through the rest of this course, you'll encounter several activities that will challenge you to equate yourself with Accenture's AI tools and apply what you're learning here to your daily work. My hope is that by giving you opportunities to familiarize yourself with our AI tools, you'll feel confident in using them to create value for our clients. So let's get started.

Executive Briefing: Getting Started with Gen AI
Introduction and Overview
Okay, there's a bunch of different ways I could begin a course about generative AI. I could begin with hype. Isn't technology wonderful? Generative AI can take care of everything now. But I could begin with criticism and tell you to beware of generative AI for it is biased, it is unreliable, it is wrong, it is deceptive. I could show you news headlines about all the jobs it's going to destroy, but I could show you other headlines about the jobs it's going to create. And okay, I'm going to talk a little bit about all of this because there are valid reasons for all the hype and for the criticism, reasons to be anxious and reasons to be optimistic about this technology. But whether you are personally enthusiastic or skeptical or somewhere in between, this is important. Generative AI is a new technology already having a massive impact on the world, and I guarantee you it is useful to understand it better, know how to use it, and just feel more comfortable with it. But this term generative AI describes a variety of different software tools and applications, including ChatGPT, Google Bard, Midjourney, Anthropic Claude, DALL‑E, GitHub Copilot, Microsoft Copilot. There are dozens of others and new ones appearing all the time. Some of these are websites you go to, others are apps you install on your mobile phone or your desktop or laptop. We're seeing generative AI features being added into older existing applications like Microsoft Office and Adobe Photoshop, and other generative AI is designed to be integrated into your own custom software and applications. But the point of any generative AI is that you provide some instructions, often in the form of a prompt, which can be a simple sentence to describe what you want. And the generative AI then generates brand‑new content, and that's what the word generative means here, that when you ask that AI for something, it's not just finding some existing file and handing it over. It actually generates or creates brand‑new results. Many of them generate text, all kinds of text from emails to poems to packing lists, stories to presentations, summaries, business strategies, conference schedules, hiring plans. But generating text also means some of them can generate specialized kinds of text like computer code. ‑Write a Python function to convert Fahrenheit to Celsius. ‑Now other generative AI tools can generate images from abstract pencil sketches to icons, diagrams, all the way to photo‑realistic cinematic images. Gen AI can also generate audio. We can have new music, new sound effects, or we can have new generated voices. It can create slide decks for presentations. We can do video processing like I showed a moment ago to change the style of an existing video. We can also make video avatars ‑and make them say our words instead of us. ‑And okay, it might seem like all these tools must be incredibly different from each other. But the way that generative AI works is fundamentally the same, whether it's being used to generate text or generate images or generate code or anything else. And that's why here, we're not just going to talk about using one generative AI tool. This is how you can get better results from any of them. And that's not always obvious because working with generative AI is often counterintuitive. What I mean by that is sometimes you will give one of these AIs a complex request. You might even secretly think, oh, there's no way it's going to do this, but it does. It instantly gives you exactly what you wanted. So you think, well, if it was good at that complicated thing, it must be really good at this easy thing. And then you give it something simple to do and it fails miserably. We're going to talk about why this happens. Along the way, we'll cover several important terms like LLM. We'll talk about prompt engineering, context windows, foundation models, hallucinations, and more. But this is a short course. So if you are looking for a deep technical dive into the details of the algorithms running behind the scenes, this is not that course. And unlike what some people would have you think, you do not need to be any kind of artificial intelligence expert to just use generative AI successfully. However, there are a few things that's worth knowing about how this works because that's how you can understand what it's good at and what it's not good at. So whether you just want to keep up with current technology, whether you want to understand which tools you should be looking at that would work the best for you or just because this is a fast moving area of technology, what you should expect in the future, welcome. Let's dive right in.

Your First Five Minutes with Generative AI
I expect many people watching this have already used generative AI. The problem is the way a lot of people are introduced to this is using trivial examples like create a bedtime story, write a poem, plan a fishing trip. And when you begin that way, it can often be tough to make the leap into actually being productive, being useful with this. So even if you have used generative AI already, for a moment, let's pretend you hadn't and just kind of begin again. What should your first 5 minutes with this have looked like? Now I could demonstrate generative AI using many different tools. We are going to begin with ChatGPT because it's the most popular, most well known of the generative AI chatbots. ChatGPT is at the website chat.openai.com. You'll need to create an account if you haven't already, but let's just jump right in and start with a prompt, "Write a one paragraph email to my boss asking for Friday off." And here's what ChatGPT comes back with. ‑"I hope this message finds you well. I am writing to formally request time off this coming Friday." ‑But watch what happens when I ask it to rewrite it to be less formal. ‑"Hope you're doing great. I wanted to ask if it's okay for me to take this Friday off." When you use a chatbot, it keeps track of context, meaning the history of chat, the relevant details that were mentioned earlier. So here, I just said rewrite it to be less formal. The AI knows that it means the email to the boss I just asked you to write. Now this is very different from, say, using a search engine where every interaction you have just begins again. Now I could keep this chat, this conversation going, but I'll start a new one for a different kind of question. Let's say I just got a message asking me to fill in for someone on a technical interview that's going to begin in 5 minutes. I need some prep. So, write some interview questions for an entry‑level web developer. Now an important point. If you're following along using ChatGPT or any other AI chatbot and you typed in exactly the same prompt I did, you should expect the results to be similar, but different. If I entered the exact same prompt again, and again, and again, I would expect a different result every time. Generative AI does not produce identical responses. There's a level of randomness and unpredictability. Just as if you'd asked 10 people to do this, you would expect 10 slightly different results, it's the same here. But let's switch gears to another example. Let's say a colleague just sent me a link to a research paper. At the time I'm recording this, late 2023, if I just have a basic ChatGPT account, I can't upload a PDF. But if I have a basic account at Anthropic Claude, I can. So let's switch over to a different chatbot. It's a PDF, but I know this is publicly available on the web, so I don't mind uploading it. And I tell Claude to summarize the main points in this research paper. And this is one of the things generative AI is great at, the idea of summarizing longer amounts of content. But let's say I looked at that summary and I saw there's something I'd like to know more about. So I'll refine it. Expand on what the paper says about point 2. It can be a great productivity tool right from the start to digest long documents or long emails into concise insights. And here's the thing. Your prompts don't have to be perfect. Most AI chatbots are pretty forgiving about punctuation and grammar. This is not like programming languages where you have to write statements within an exact perfect syntax. I could've written these requests in many different ways. However, a little later, we're going to talk about the different kinds of things you'd say in your prompts to help guide the AI to better results. But when you're starting out with generative AI, do not get hung up on crafting the perfect prompt right away. There's a lot of people out there that tell you they have the perfect prompt for some business situation. They're usually trying to sell you something. The key is to have this attitude of continuous experimentation and revision. Treat the initial prompt as a starting point. Ask the AI to build on those ideas and rewrite its responses. Try different prompts from different angles. Tweak the prompts that don't work well, and sometimes just give up and start again. There is an art to prompting, and it develops through actively engaging with this. So rather than expect instant perfection, just embrace this exploration idea, see what works, see what doesn't, and improve along the way. So, we've covered helping write emails and then rephrasing those emails, creating interview questions and then refining those questions, asking for summaries, then expanding on those, and we're just starting to scratch the surface.

Generative AI That Isn't ChatGPT
The generative AI marketplace is evolving rapidly. There are new tools, new applications, and new businesses appearing all the time. ChatGPT often gets the most attention, but there are many other powerful gen AI tools out there. Now we can't possibly cover them all here, and we don't need to. But it is useful to have kind of an overview of the different areas of generative AI because that's the first question. If the point of any generative AI tool or application is that it generates something, well, what does it generate, text, images, audio, video, something else? So let's start with text because even this has multiple different aspects to it. We have the chatbots designed for us to have these back and forth conversations. ChatGPT from OpenAI is the most well known, but there's also Google Bard, Anthropic Claude, Microsoft Bing. Inflection has the Pi chatbot. Quora has the Poe chatbot. Now, chatbots are broadly similar in the way you interact with them. If you know how to use one, you know how to use any of them, but they do have different intended use cases, different features, different capabilities. For example, at the time I'm recording this, the end of 2023, the current version of ChatGPT only knows about things that happened before April 2023. Because the way it was built, and we'll talk more about this later, it has a knowledge cutoff point. Now a quick sidebar, this cutoff point is periodically updated. So at the time you're watching, it may be more recent. Now how do you know? Well, it's a chatbot. Just ask it, what's your knowledge cutoff point? Some chatbots are designed in such a way where if you ask them about something more recent, they can go out to the web and find up‑to‑the‑minute information. Now, there are differences. For example, some chatbots allow you to upload documents and provide links, others don't. Now all of these features change and improve regularly, but they're chatbots. If it's not obvious what they can and can't do, ask them. But beyond that, their intended use case can be different. So ChatGPT is designed to be as general purpose as possible. You can ask it to write a bedtime story or create a poem or summarize a complex business document, write a business case. But Inflection's Pi chatbot, now that's designed more to be a personal companion rather than a productivity and research assistant. It's something you use for talking through personal decisions and act as a sounding board, but we also have text‑focused generative AI that are more specialized to a specific business area like marketing or content creation. Examples here would include Jasper and Copy.ai. Now while they do generate text, they are much more structured. They provide templates and guidance around specific uses. And for software development and code generation, you can use many of the general purpose chatbots and just ask them to generate code or also kind of as an educational tool. You can paste in some code and ask them to explain it to you. But there are also specialized applications like GitHub Copilot, which integrates into a programmer's development environment to suggest code as they type. But another major category of these tools deal with images like DALL‑E, also from OpenAI. This is an AI designed to create images from any text prompt. Similar tools include Midjourney and Stable Diffusion. Like the chatbots, we use prompts here, but the prompts look a little different. There's sometimes less of a regular sentence and more of a list of qualities and characteristics you want from the new image. Because designers and artists often have their applications they've been using for years, we're also seeing generative AI features being added into popular existing design tools like Adobe Photoshop. Photoshop now has a tool called Generative Fill. I can type a description of what I prefer to see in this section of the image, and it will give me several different options for this. Now over to video, there are tools like Runway ML and Kaiber that can generate video from text prompts. Now right now, the video tools aren't at the point where you could just provide any prompt you want and get production‑ready results. Some of the results are a little strange, but there are some more specific targeted areas of video creation that it's useful for. One of the things we can do is work with video avatars. Organizations like HeyGen, Synthesia, and D‑ID all provide options where you can provide a script, and they will generate a virtual person speaking that script. There's also options to use generative AI for audio. We can have it generate music or sound effects or voices. Companies like ElevenLabs specialize in voices. I can choose from a selection of precreated ones. I could even clone an existing voice by providing some samples. ‑And unlike the computer voices of old, the delivery here is often very realistic. ‑Now a lot of the current generative AI products focus on one kind of thing. They only generate images or only video or only text, what's often called a single modality. And the reason I mention this word is we also have this growing idea of multimodal generative AI where the same AI can deal with more than one modality. It could deal with text, and images, and video. But as these tools develop, we're also seeing more and more useful combinations of them. For example, I can ask ChatGPT for an image. And while ChatGPT doesn't directly create the image, it could take my basic prompt and then pass those over to DALL‑E to actually create those images. So, the power becomes in tying several of these together. Another example, because we have generative AI that can do text translation from one language to other, and we also have the ability to do audio voice cloning, and we also have the ability to do video processing, if you combine these three things together, that allows us to have video translation where companies like HeyGen and Synthesia will take my video that I've recorded in English, translate it into other languages, then also clone my voice and process the video on my face to make it sound like and look like I'm actually speaking that foreign language. If you combine these three things together, (Speaking in French), (Speaking Japanese). So first, think about the kind of output you need and whether you want a more general use or a more specialized use. And new generative AI tools are appearing all the time, and they often have a lot of hype around them, so do take the time to properly evaluate your options.

How Generative AI Works
Generative AI uses an approach called machine learning. And what that means is these systems all learn by example. And to do that, they need a lot of examples. So the companies developing any of these generative AIs have to begin by gathering massive, massive amounts of data to analyze and learn from, whether that's text or images or code. So, a text‑based generative AI is built by analyzing millions of text sources like webpages, books, articles, scientific papers, whereas an image‑based generative AI will have been trained on countless images, photographs, illustrations, diagrams, and they need staggering amounts of data because they're trying to identify patterns and similarities in the data. And the combination of all the data that they're trained on, together with your suggestions or your prompts, allows them to generate that brand‑new content. Now a quick sidebar. People often wonder, what do you actually call this? I mean, is it a program? Is it an application? What is it? Well, we call it a model. The end result of this training process, which is very expensive and very time‑consuming, is a model. We say that we have trained the AI model on all of this data. There's even more specific terms. So when a generative AI is text‑based, meaning it's been trained on incredible amounts of text and language, we call it a large language model, or LLM. Now if the model was trained on some other kind of data like images or video, well, we're not going to call it a large language model because it isn't dealing with language. The term you'll often hear is foundation model. Training a generative AI model is very time‑consuming and extremely expensive. The large commercial generative AIs, the ones used by ChatGPT or Google Bard, they are estimated to cost tens of millions of dollars in computer costs alone just to train the model. They need these massive server farms and tons of equipment to do it. And it's one of the reasons why there is a cutoff date with what ChatGPT knows about. Because that LLM took so long to train, it was trained up to a specific date. You can't just do it again the next day because it costs incredible amounts of money to train them. Now it's a common misconception to think that because these generative AIs are trained on millions of existing examples that they store all of that data they're trained on, but they don't. They try and recognize patterns in the original data, but they do not store all the original documents. So a generative AI model is not like a database where you can just look something up. Here's what I mean. If I was a generative AI model and I've analyzed millions of documents, including multiple documents that contain the phrase, "It was a dark and stormy night", now I could recognize this pattern, recognize this occurrence of words one after the other. And after being trained, if you then ask the model, well, what comes after the words, it was a dark and stormy? The model will say, well, night, probably. I mean, statistically, if somebody writes it was a dark and stormy, the next word is probably going to be night. However, if you now ask the model, okay, now tell me every single document that contained that phrase and the rest of the contents of those documents, it doesn't know because it didn't actually store all the documents it analyzed. It stored the results of the analysis. So while it's really good at recognizing patterns and making new predictions, it is not good at just looking something up. And while it might be an oversimplification to say that generative AI is like a big autocomplete system, there is an element of truth to that. Fundamentally, it is trying to figure out if you wrote these words or these sentences, what is the statistically most likely next word or sentence or paragraph? But also, because the model is trained on massive amounts of data, everything from scientific papers to novels, song lyrics, equipment manuals, the model doesn't actually care whether it's looking at the text for a washing machine manual or looking at the text for a fantasy novel. It's just text. And an LLM does not make a distinction between fiction and non fiction. It doesn't understand true and false. It is just trying to recognize patterns in the data. Now let's take another phrase like "That was a massive waste of", and what comes next, massive waste of time, massive waste of money, massive waste of time and money, massive waste of my time, your time, the company's time? Now all of these are possible, and they would all work as the next word or phrase after that beginning. But if you had previous context, let's say you also knew all the sentences prior to this one, it allows the predictions to be better and more accurate. And it's why a lot of LLMs will talk about having a larger and larger context length or context window, meaning what is the overall amount of things that they remember? What is in their working memory? What did they understand about this particular interaction? But here's the thing, this idea that there are often multiple possible answers is why generative AI can give you results where you understand why you got that result, but it's completely wrong.

When Generative AI Goes Wrong
Generative AI models are amazing at matching patterns and making new combinations, and they can often seem like they understand things, but that's a mistake. You see, these AIs all do their best to generate new results that are convincing and believable. It doesn't mean that the results they generate are actually correct. There's even a term in generative AI called a hallucination where the AI basically makes up an answer. It might sound right and is often incredibly convincing, it's just not true. I've had multiple experiences using gen AI for research where it's made up a very realistic, convincing answer, including citations. But if you actually looked up the publication mentioned in that citation, it doesn't exist. There's been new stories about attorneys using generative AI to build out their case files and it generating references to prior cases that never happened. And again, it's because of the way generative AI works. It recognizes patterns in data, and it's extremely good at using those patterns to generate statistically likely results. But just because an answer is statistically likely, it doesn't mean it's true. So while generative AI can give you amazing results, we're still at the point where you need to factcheck anything you get from them, particularly if you're using them for any kind of technical reference or technical explanation. Now sometimes it's a bit more useful to use the image tools to better demonstrate some of the issues with generative AI. So I'm going to give the same prompt to several of the image‑based generative AI tools that an image I want is a glass of water with a lump of sodium in it. These are the results from DALL‑E, these are the results from Midjourney, and these are the results from Stable Diffusion. For those of you who remember your high school chemistry class may be itching to point out a piece of information, which is what happens if you drop a lump of sodium into a glass of water? Because the answer is it explodes. Pure sodium and water causes a massive exothermic reaction, something that is not being represented by any of these images. And that's because they're doing a great job of pattern matching. They're taking words like glass, and water, and sodium and combining them together. But most of the images they've seen with the word sodium were probably pictures of salt. I can understand why I got the results I did. It's still wrong because these generative AIs are not built with a fundamental understanding of the world. They don't understand consequences. They don't understand cause and effect. They're amazing at matching patterns and making new combinations. They can mimic, but it doesn't mean they actually understand anything. Now is this improving? Absolutely. And there are ways to mitigate against some of these situations. For example, if I use ChatGPT as a middleman to help me build that image prompt of sodium and water, the fact that ChatGPT is built on analyzing text, which often would have patterns talking about sodium and water will explode, then ChatGPT might not actually generate those images, but it could generate a more useful prompt and then pass that over to DALL‑E to generate the image. Now this might not be perfect, but it's more along the lines of what I wanted. Another common concern with generative AI is the idea of bias, and it's easy to see bias in generative AI. Use any of the image tools like Midjourney, DALL‑E or Stable Diffusion and ask for an image that represents a job like I want a picture of a professor. You get multiple options, but do you see a certain similarity in the results? Let's try another. What does a software developer look like? And one more, how about a photo of a preschool teacher? Now we can understand why we get these results. These tools were trained on millions of existing images. Images with these keywords have historically skewed to a particular gender, age, and skin color. But the AI can up reinforcing this, as if all professors have to be 60‑year‑old bearded white guys. Now, can you get generative AI to be more diverse? Absolutely, but you have to ask for it in your prompts. And to ask for it, you need to notice when it's happening. And while it's easy to see bias in a visual example like this, the same idea also applies to the way text‑based generative AI works, but it can be much harder to recognize. Generative AI is fantastic, but it does bring new issues, not just hallucinations, but the potential effects of misinformation along with issues of data privacy, and content ownership, and many larger issues around the impact this is going to have on many professions.

Getting Better Results from Generative AI
Getting better results from generative AI often comes down to the quality or creativity of your prompts, meaning the questions you ask and the commands you give. There's an idea called prompt engineering. And this can mean different things to different people, but let's just take it as the idea of applying some structure, and formality, and thought to our interactions with generative AI in order to steer it towards the results we want and when we don't get the results we want how we then interact with the system and how we refine and rephrase those prompts. There's this idea that with slight changes in the way you ask for things, you'll get very different results. Some of the most common suggestions to incorporate in your prompts include the idea of a specific persona or profession where you can tell an LLM to act as if it's a type of person. It can be a job role, act as a marketing copywriter, act as a physics professor, act as a financial advisor. You can even ask for specific people like historical figures or fictional characters. But there's one thing I personally find very useful here, which is the idea of flipping the roles. Here's what I mean. See, I see a lot of suggestions to use generative AI in a way that tries to replace the person writing the prompt. For example, I write and teach technical content. And a lot of people recommend that I might begin my prompts with words like act as an experienced instructor, act as a skilled trainer, act as an expert educator. I hate this recommendation. I am the experienced instructor. That's my job. I want gen AI to help me, not replace me. And I don't like the internal message I'd be sending to my own brain that I have a core competency, let me just give it to the machine. Now you can do this, but don't be annoyed at generative AI for taking your job if you're literally handing it over. But what's the alternative? Well, we can flip this around. Don't ask ChatGPT to act as an instructor. Instead, tell it to act as a puzzled learner and ask me three questions about joining tables in SQL or how variables in this language compare to variables in that language. I find it far more useful to have generative AI act in this role. And I often don't need the LLM to act in a specific role. I think that's sometimes overused. Just tell it what you need. You can be specific about the audience. Explain as if I'm 10 years old. Write as if you're talking to a room full of software developers. You can also say what the desired tone should be, and I don't just mean formal or casual, but being extremely specific about how you want those results to feel. You can tell it what exact length you want, whether you want a short email or to write five tweets or you need 500 words or three paragraphs or two sentences. The more specific and creative you can be with the prompts, the more creative and useful your results. Now, in 2023, it was very common to see headlines like this, ‑"Prompt Engineering: The Hot New Skill Employers are Seeking." ‑"Prompt engineering, the hottest job in tech. ‑"Prompt engineering: the most in‑demand profession of the future. ‑But I already believe this idea of everybody needing to be an expert prompt engineer is becoming less and less important. Now right now, it is important to be comfortable with writing generative AI prompts, but the tools themselves are quickly improving on this. They're taking even basic prompts and better reacting to what we're actually asking for. And it might sound like an odd thing to say, but the prompts were never the most important part of this. What's more important is your approach to them, not worrying about the perfect prompt, but keeping that attitude of experimentation and revision. And as the tools continue to change and improve, that is much more important. But the single most important thing to feel comfortable with generative AI, where it becomes just more intuitive to recognize what it's good at and what it isn't, is to use it again and again. Just start baking it into your life. So make ChatGPT or Google Bard or Anthropic Claude your home page. Get into the habit of using generative AI where in the past you might've used a search engine or Wikipedia or even just journaled in your own document. And if you want to go a little deeper, watch another topic in our Generative AI Foundations series. But thanks for joining me. I'll see you next time.

TQ TV: Jan 2024
Large language models
Hello, and welcome to TQ TV. I'm Ronnie Trouton, and in this series of short videos, we're going to be talking about generative AI from an Accenture perspective. Our TQ training is what allows us to be able to understand and explain key tech topics, and gen AI has the potential to change the way as we work forever. We'll be getting insights from our global AI experts, learning what and what not gen AI can do, and discovering the ways we're using gen AI right now in Accenture, ethically and sustainably. So let's begin by exploring the different types of AI out there. Large language models, gen AI, what's not to love? There is nothing hotter in the world of tech right now. Everybody wants it, so we've got to know all about it. Before we get too excited about the possibilities and decide that gen AI is the answer to absolutely everything, we need to sift through what we know, separate the hype from the hyperbole, the facts from the fiction, and get to the heart of LLMs and who better to explain why foundation models in gen AI may not always be the answer than our Chief Technology and Innovation Officer. Let's welcome back, Paul Daugherty. ‑Large language models are a form of foundation model that's really large. It takes more energy to train them as a result and more energy to run them. They require a computational capacity that's much larger than other forms of AI, so why is it for tasks where its power and strength aren't required? ‑So it's like instead of using your cute little nightlight to read while your partner sleeps, you use the 200,000 watt version. Bright, but not smart. Paul? ‑Also LLMs are good at understanding and contextualizing language, but not every AI use case requires that level of context and comprehension, and that's why we recommend our clients take a holistic approach to AI by using a combination of diagnostic, predictive, and generative AI capabilities. ‑Okay. Sounds like it's time for AI types 101. Roll it. ‑Diagnostic AI answers the question, why did this happen? It's great for analyzing and planning, as well as segmenting data. For example, in digital manufacturing, diagnostic AI can be used for preventative maintenance and quality checks by analyzing images and video. Predictive AI answers the questions, what might happen in the future, and what should we do next? Predictive AI can forecast, make models, and of course, recommend actions. In retailer consumer goods scenarios, this could mean forecasting sales of a particular product type in a particular region to plan for inventory and supply. And of course, generative AI identifies patterns and structures within existing data to generate new and original content which can be applied in a few different ways. Recently, for a broadcast network, we used generative AI to develop a new summary engine that uses transcripts from livestream sports events. ‑So where on earth can we see all these types of AI working together? Back to Paul. ‑Yeah, absolutely. This holistic approach with a blend of all three types is something everyone in Accenture sees in action actually every morning. Good Morning Accenture uses the full spectrum of artificial intelligence capabilities, classifications, segmentation to hyper‑personalization, and content generation replace thousands of emails, newsletters, and meeting invites with a personalized vehicle that patches all the key info that you need into one single email. In less than a year, this holistic use of AI has helped us reduce internal corporate email by 46%. ‑720,000 inboxes send their thanks. We all know AI can do incredible things, but we also know it means a massive shift for organizations across the world. Back to Paul for a final word. ‑To really maximize the value of data, every organization will need a holistic set of AI capabilities. Those capabilities must include talent management, new processes, and new ways of working to extract the value of the data, and that's why it's such a massive shift for today's organizations, and this is where humans and machines truly start working together. ‑We should all know, understand, and be able to explain the advantages, implications, and potential of all types of AI. Together, these three key types are going to be at the very core of every business, but for now, let's keep our focus on gen AI, understanding when and when not to use it, what it can do, and what its challenges are.

Foundation model fundamentals
Time to get down. Because for this section, we're going right down to the foundations to talk AI foundation models. Get ready to explore the different types, how we use them, and the results they deliver. Here's Accenture's chief artificial intelligence officer, Lan Guan, to tell us what makes foundation models so special. ‑It's great to be here to talk about foundation models. They are the foundation of generative AI. All generative AI applications, including ChatGPT, Bard, and DALL‑E 2 rely on vast amounts of curated data in foundation models. A foundation model is trained on a broad scale of data that can be adapted to perform a wide range of downstream tasks. It's important to note that prior to generative AI, most AI and machine learning models were typically discriminative models and pattern recognizers. They noticed differences within the data and sorted it for specific use cases. This is a person, this is a person, this is a microwave, not a person, and so forth. ‑So, just to clarify, person, microwave, but that's the old way. This is a person, this is a microwave, that's not how foundation models work. No, foundation models have vast powers of interpretation, automation, and content generation. They make and remake content. So, what makes them able to do this? What do foundation models have that traditional AI does not? ‑First, they are pre trained. That means they learn from data before it's clear what questions it will be asked in the future. Next, they are self‑supervising. Just as common sense helps humans learn new skills without requiring massive amounts of teaching for every single task, these models can continuously adapt to common sense reasoning. Traditional AI models needed tons of examples in order to correctly identify something. A self‑supervising model can make connections between examples to increase their performance accuracy. Can you tell the difference between a spotted cow and a Dalmatian? Probably. Can gen AI? Probably. Traditional AI, not so much. And third, foundation models can maintain context over multiple interactions. There's no more model forgetting with foundation models. They use attention mechanisms to keep the context from previous interactions. ‑Okay, so now we know that foundation models are essential for gen AI, as they're pre trained on broad datasets, they're capable of learning, and being self‑supervising, plus they maintain context from every interaction. But are there different types of foundation models out there? Lan? ‑There are different types of foundation models, three so far, in‑application models, proprietary models, and open‑source models. Let's start with in applications or copilot models. Many third party and open‑source models are already embedded in the workflow of existing enterprise applications, and they typically use in‑application, domain‑specific data. For example, Salesforce recently announced Einstein Copilot, which is seamlessly integrated into the side panel of the Salesforce application's user interface and allows users to ask natural language prompts directly within Salesforce CRM. With that, a customer service representative could use Einstein Copilot to create a workflow that automatically generates a refund for a customer. Next, we have proprietary models. They are prebuilt, state‑of‑the‑art large models. They are ready to use, but with very limited ability to customize. They are closed in the sense that the source code cannot be edited or customized. For example, Accenture uses Open AI's GPT‑4, a closed model, to create an application that generates first drafts of RFP responses for our sales team. The third type is the open‑source model. In contrast to the proprietary model, these open‑source models are free to use, open for customization, and have greater transparency in terms of sharing underlying architecture, weights, training dataset, and even infrastructure needed. The Llama 2 model, released by Meta, is an open‑source model widely used by the developer community. ‑So, now we know three reasons why foundation models are so powerful, and we know there are currently three types of AI foundation models, but we also know there's no one size fits all for foundation models. Every organization will have different needs and purposes. So, what factors should we consider when we're choosing a foundation model? I'm hoping there are three of them. ‑There are four factors that I always suggest you consider. ‑Okay, not three. ‑One, open versus closed. To what degree do you need your model to be transparent and explainable? In the banking and insurance industry, it's a regulatory requirement that you reveal model details in terms of the data mix, model architecture, model weight, and infrastructure needed. A closed proprietary model won't be able to tell you this. Two, adaptability. How customizable do you need your model to be? Will you be adding your own large amount of data to the mix? If customization is critical, an open‑source model might be your best choice. Three, modality. Does the model communicate strictly through text or does it offer other options? Can it produce content in other formats? We work with a large retail client to choose Google's PaLM 2 Bison model to process two billion images on their e‑commerce catalog to improve search and deduplication of millions of SKUs for their customers. And finally, four, enterprise readiness. As clients go beyond proofs of a concept, it's important to ask which models align with their data policy, their security needs, and technology landscape, and, of course, which models offer the right mix of the out‑of‑the‑box capabilities. ‑So, if we're trying to bring gen AI into an organization, there's different factors to consider. There's different foundation model types to choose from, all with their own talents, and complexities, and quirks. We have to think about how different models can coexist, how they can be customized and contextualized within an enterprise. That's quite a lot. So, what should chief technology officers do and what are the strategies that will help? ‑We know that each organization is unique and will use AI differently. That's why we break it down into three main strategies, buying, boosting or building. Each comes with its unique pros and cons directly related to your cost, complexity, customization, and control preferences. Buying means to purchase big, large models off the shelf. All we do is to prompt engineering with your own data. They are easy to access, but it takes some work to be specific enough in prompting to get something useful back. Boosting means to customize the model, usually by adding company‑specific data. Building means that we build a bespoke foundation model from the ground up. It's completely unique, but also a lot of work and very expensive. Each of these options makes sense, depending on the organization's goals and its maturity in the AI space. As clients grow in their confidence and wake up to the untapped power of their own data, they often revisit the strategies to expand their use of generative AI. Buying might have made sense at the start of their journey, but boosting and building might be the way to go in the future. Remember, data is the business's most distinctive competitive advantage. The great thing about generative AI is that it is general purpose. ‑A key to learning about gen AI is never being afraid to ask questions. So, Lan, does that mean general purpose is the GP in GPT? ‑Technically, GPT stands for generative pre‑trained transformer, but I like to think that it has a second meaning, general purpose technology. You can leverage general purpose technology for all sorts of a task. ‑Okay, so if I'm getting it right, put simply, general purpose technology can be used for all sorts of tasks, unlike older AIs, which could only generally do one thing well. Plus, gen AI can be adapted to learn new talents through prompting and data training, right? ‑And that very adaptability shifts the paradigm in a huge way. It gives us and the AIs we use immense power to generate answers to questions we haven't even anticipated yet. The potential for the future as generative AI gets democratized is vast. ‑And thanks to Lan for taking us through a complex topic. Final thoughts, please. ‑Navigating the unchartered waters of generative AI can be daunting, especially for organizations that are new to the technology. Building a generative AI capability requires a complex decision‑making process with careful thought to align the gen AI strategy with the corporate strategy. It's important to have the right partner to help navigate these waters. ‑But now it's time to leave the foundations and elevate our thinking to a much higher plane because we are going up, up, and up to explore the importance of cloud and data to gen AI, next.

Starting with cloud & data
To anyone who is interested in taking advantage of the power of gen AI, we have one thing to say, excellent! Okay, maybe not just one thing. This is where we talk about the if because while every company is at a different place in its digital journey, there is a certain threshold a business has to reach if it wants to use gen AI effectively. It's like having the biggest hot tub you can find installed in your garden, but then wondering why your party is ruined because it doesn't do much without power and water. Gen AI can't function without the right infrastructure, and those key supporting technologies are cloud and data. So, without cloud and data, gen AI is like a race car without the engine, a laptop without the battery or a rose without the bloom. So, let's tackle the thorny issue of what steps businesses need to take to get gen AI ready. Over to Sen Ramani. ‑Cloud and data are the price of entry for businesses that want to use generative AI. Without the processing power of the cloud, as well as the quality data, the amount of value a business can get from AI is minimal. Sure, every company can dive in right now and find some value from generative AI. But the real value and tremendous impact of a large language model is going to be limited for any company that hasn't laid the right technology groundwork. In order to get the real value out of a large language model, a business must do four things. Number one, move to the cloud. Number two, modernize their data platform. Number three, have high quality data. Number four, put data governance mechanisms in place. If a business has done those things, they can get the greatest value from a large language model. That value comes from having the ability to fine tune the large language model with its own proprietary data to meet its unique needs. ‑Of course, the real value in an LLM is in the tuning, and that means one thing, data. Over to you once more, Sen. ‑AI analyzes data to recognize patterns, predict outcomes, and recommend actions, but AI is only as good as the data it receives. The more accurate, accessible, and varied the data, the better the results. And as more people interact with the AI, generating even more data, the more its knowledge and responses improve. More data needs a lot of storage. You know where we're heading next. ‑Only the cloud has virtually unlimited processing power that today's AI applications demand, and cloud environments can store the vast, scalable datasets that make machine learning possible. All these providers are bringing competitive offerings to the market, lowering the barriers of entry for all types of organizations and giving AI the critical mass it needs for mainstream adoption. ‑That's cloud and data, the engines of all AI, but with such great power comes great responsibility. So, let's move on to see what we have to do to use gen AI responsibly.

Responsible Gen AI
The race is on. Every company is competing to win, but the cost of getting it wrong is very high. From leaking confidential data to bogus and harmful health advice or false accusations, we must do all we can to help ensure generative AI is used responsibly and ethically. Here to tell us more about the specific risks associated with generative AI is Arnab Chakraborty, Accenture's global lead of responsible AI. Arnab, I'm not going to lie. This all seems a bit overwhelming. Should we throw in the towel and agree the race is just too scary? ‑I understand your concerns, especially with all the news, but I am here to let you know there are ways to compete and win the AI race, which will have positive outcomes for everyone. But first, we must understand the potential business and the risk hazards. Gen AI introduces a unique set of risks. ‑On a scale of one to still scared, I have to say this is doing very little to calm my nerves. Please tell me we're doing something to mitigate these risks. ‑If it's any consolation, you are not alone. Businesses and governments are concerned about these risks too, and the reality is that many don't know how to approach them. ‑So, how can C‑suite leaders navigate these risks and challenges to leverage generative AI across their business? ‑Accenture has a framework for evaluating and managing gen AI risks and compliance with our responsible AI approach. For any enterprise, responsible AI means taking intentional actions to design, deploy, and use AI to create value, build trust by protecting from the potential risks of AI. Responsible AI begins with a set of AI‑governing principles, which each enterprise adopts and then enforces. Our Accenture's responsible AI principles includes human first, fairness, transparency, explainability, and accuracy, safety, accountability, compliance, data privacy and cybersecurity, and sustainability. ‑So, how can leaders who want to leverage the power of gen AI navigate these risks? ‑Here are the five actions enterprises need to take for establishing a responsible AI foundation. Number one, setting up the AI governance, which agreeing and adopting the responsible AI principles with clear accountability and governance for responsible design, deployment, and usage of AI. Number two, conduct AI risk assessment, understanding the risks of an organization's AI use case, applications, and systems through qualitative and quantitative assessment. Number three, enabling systematic responsible AI testing. Perform ongoing testing of AI for human impact, fairness, explainability, transparency, accuracy, safety, leveraging best of breed responsible AI tools and technologies, and enable the mitigations. Number four, ongoing monitoring and compliance of AI, ongoing monitoring of AI systems and overseeing the responsible AI initiatives while executing mitigation and compliance actions. Number five, workforce impact, sustainability, and privacy and security. Responsible AI compliance program will need to engage cross functionally to address workforce impact compliance with laws, sustainability, privacy, security programs across the enterprise. ‑Excellent! Can you tell me some more about sustainability? ‑AI, as a technology, is compute‑intensive. Since 2012, the amount of compute used in the largest AI training runs have grown by more than 300,000 times. AI generates significant carbon emissions. According to Stanford's AI Index, it took equivalent of 502 metric tons of carbon dioxide emissions to train GPT‑3 last year. This is the equivalent of 109 cars yearly emissions. AI development decisions have an impact on energy efficiency and, hence, cost. An experiment showed that to gain an additional 2.5% accuracy improvement, the model required more than 15 times more energy in additional training. Organizations need to design and deploy AI responsibly with sustainable principles to consider the impact on the environment with appropriate steps taken to mitigate the negative impact. ‑That's pretty impressive. Can we talk a bit more about how Accenture is helping our clients in this area? ‑We have developed a dual‑speed approach to helping clients implement responsible AI with trust and confidence. We have an end‑to‑end responsible AI offering to help clients set up their enterprise responsible AI compliance program. In addition, we have an offering on responsible AI in a box that is designed to help a client apply responsible AI immediately to their AI use cases and pilots. ‑Can you give me an example of the work we're doing with plans? ‑For a global retail client, we built an operating model that includes executive leadership and middle‑level management, identified the clients with tolerance, and developed a risk stratification approach for their AI. We then defined a framework for assessing fairness and mitigating the buyers throughout their AI model development lifecycle. We piloted the framework on two AI use cases, utilizing the implemented toolkit. Accenture also created risk assessment, measurement, and scoring processes to evaluate AI model risks and establishing risk control stage gates for bias assessment and management. Finally, we delivered a comprehensive training plan for executives and practitioners as part of their responsible AI program. ‑I'm feeling much better about this. I'm so glad to hear that Accenture is leading the way with responsible AI for our clients. What can we, all Accenture people, do to help ensure that we use generative AI responsibly? ‑Yes, bookmark the responsible AI home page to review the seven principles for including responsibility by design. Under the assets and the solutions, you will find a link to the Responsible AI solution tablet that will support your client conversations with the latest insights and tools. And last, but not least, the learning section will guide you to even scenario‑based learning opportunities. ‑Great stuff. I feel like we're on the right track. Does Accenture also have a place with guidance on specific tools and their responsible use for internal purposes or for helping our clients? ‑Of course. We have this too. There is a generative AI legal playbook, which outlines the key risks of using third‑party generative AI tools, examples of use cases, and their risk profiles and potential mitigation strategies. This playbook will be updated over time, so I would suggest people bookmark it as a key reference for the future. So now, you know all about the fundamentals. We can all build and to get us off to a great start and win the gen AI race. ‑It's very clear that this race is a marathon, not a sprint. And to make sure that future news stories about gen AI are good news stories and to enable you to make the right decisions, be sure to check out the exercise files section of this course. Download the hands‑on activity on the responsible use of gen AI and come back to work on the assignment. I know we're all very busy, but taking a small bit of time to do this will help prepare you for when you or your client starts working with gen AI in a big way. Speaking of which, our next topic is all about how businesses use gen AI.

How businesses will use Gen AI
TQ isn't just about knowing the theory, it's about understanding the practice, too. So, in this episode, we've got a team of our global experts to talk through real‑world examples of how we're using gen AI right now. We've broken the work we do into three categories, the ways we help our clients with gen AI, the ways we're transforming our services with gen AI, and finally, how gen AI is transforming our corporate functions. We've asked Sen Ramani to dive deeper into these three categories. ‑Let me unpack the three categories for you. Category A is the work that we do for our clients, gen AI strategies we build for them, helping them identify the foundation models, helping them deploy or fine tune. Category B is about changing how we sell, solution, and deliver. Category B is all about improvements to our own ways of working in client‑facing functions. Let me give you some examples, writing code with the assistance of GitHub Copilot to reduce errors and increasing efficiency or other examples like the leveraging of the gen wizard and gen AI capabilities within synapse that our technology and operations colleagues do as well. Let's look at category C now, transforming our corporate functions, assessing the opportunity and impact of AI on our non client‑facing functions like finance, HR, marketing, and undergoing the related transformation activities to realize those impacts. Examples of category C are providing a self‑service gen AI chatbot to answer common HR questions for employees, using AI to screen contracts for legal risks or other compliance exposure. ‑Okay, so there's three categories of gen AI use, and we've got three experts lined up. Let's hear more about how we're working with clients and gen AI right now, starting with Nicholas Whittall, our diamond account lead on a $46 billion retail client with close to 1,000 stores across the US and Canada. ‑They came to us about six months ago with some pretty severe cost takeouts and needs while continuing to drive an improved customer experience. And so, the level of cost takeout through location has been pretty fully exercised, and technology was the next real frontier for us to embark upon and specifically gen AI in its ability to transform the customer experience. What is the customer experience today and how might it look going forward? A customer interacts with our client often through chat, and that is a fairly frustrating interaction. The second thing is once a customer does get through to an agent, if that's required, the agent themselves need deep, deep, deep product knowledge of what might be going wrong within the customer's home relative to a product set that the customer may have bought from our client. ‑So, we've got a chatbot who can't understand the questions customers are asking and human agents who haven't the depth of knowledge to solve problems when customers get through. Very frustrating. So, Nicholas, how is gen AI transforming this client challenge? ‑Well firstly, gen AI is being used in the chat to truly understand the intention of customers reaching out to get support. And that is a critical, critical aspect of retaining that customer in their interaction with our client. With gen AI and in partnership with Google and their CCAI, Contact Center AI Capability, we're able to follow the flow of the conversation through chat a lot more accurately and understand when a chat needs to be escalated into a live voice agent interaction. Once that live voice interaction is triggered, the gen AI capability is summarizing the chatbot conversation that has occurred to date, giving that agent full context around what the customer is going through so that the customer doesn't have to begin at square one, explaining the issue that they're seeing to a live agent. Second for the live agent, they're able to receive real‑time information about the product set, the root cause analysis of what might be going wrong with the product, and how to address that issue in real time. And that is massively important, and critical, and impactful for the customer to have experienced agents who are able to resolve the issue the first time that they reach out to our client. What that has allowed our client to do is collapse 19 very discreet lines of business with very, very deep specialized knowledge of agents in every single line of business into a single universal agent. And that allows our client to reduce their spend from $300 million. We'll be targeting around $25 to $30 million of cost takeouts in the next financial year with the glide path of really addressing 30 to 40% of their total costs in their contact center while improving the complete customer experience. ‑Thanks, Nicholas. That's a very significant reduction in spend and increase in customer satisfaction we created with gen AI. So, from our three categories, that's clients. Next, we're going to hear from Luke Higgins about how our own use of gen AI is reshaping the services we provide and helping us approach customer challenges in totally new ways, which means we can offer solutions that previously were not possible for our clients based on his gen AI experience with beverage manufacturer, Lion. ‑When a business user calls the technical support, gen AI immediately takes action by comprehending and summarizing, transcribing the phone call into a support ticket that represents the nature of the incident. From here, gen AI enriches the ticket with details around the possible root cause of the incident, resolution steps, and links and automation workflow to enable the fix. The result, a 51.5% reduction in the time it takes for the support team to resolve an incident for our business users at Lion. During the implementation of Accenture's generative AI solution at Lion, three pivotal lessons emerged that will further shape our future endeavors in this space. First, meticulous data curation stands as the bedrock. Accurate, unbiased, and contextually relevant content hinges on precisely documented delivery knowledge to ensure the creation of meaningful new outputs. Secondly, employing prompt layers to provide the context and constraints for the generative AI to craft precise outputs that are based on standardized delivery inputs. This helps ensure tailored, high‑quality content is generated that aligns with user expectations. Lastly, robust collaboration among automation architects, engineers, domain experts, and the business is essential to the development of holistic solutions that genuinely meet user needs and expectations. These lessons help form the foundation of our approach, guiding how we build and bring this new transformation technology to our clients. ‑Great learnings. Thank you, Luke. And our final example of gen AI in business today is very close to home, helping us make the right kind of decisions right across the organization. Over to you, Priya Raman, lead of the corporate data and analytics office. ‑So let me show you what the power of connected data can do to drive predictive insights for decision‑making across the organization with the 360 value navigator. So to start with, we look at the 360 value outcomes, what matters the most for our organization, which is not just financial outcomes, but experience outcomes, talent outcomes, and they're all connected to drive the 360 value outcomes of the organization. So we're not just looking at where we are, but it also gives us an opportunity to look at where we are going with the industrialized AI and ML models that run in the background. It allows us to go deeper to say, I want to look at the financial summary. It allows us to look at all the details of the next level of drilldown of what the financials are. But it not just connects sales data, but it also connects revenue data, working capital data, cost data, and profitability data together. And you're able to not just look at that at a market‑to‑market unit level, but you can look at it in various different configurations to drive the outcomes that you want to drive with the business. And then in terms of predictions, where we are going with the AI ML models running in the background around this connected data. And if you don't like where we are going, we start to look at what are the levers that we can toggle up or down, whether they sit in HR, finance or sales, to understand what the impact of toggling a lever is on profitability as we go ahead. Now, to add the cherry to the cake, what we have done is we have added the power of generative AI so we can make all of this very relatable and talk to the data in an easy conversational manner. So instead of going through all the analysis that I showed you, you can just straightaway ask a question, how are we doing on delivered CCI in North America? It not just tells you how you are doing, but it also allows you to ask the next level of contextual questions, which is why am I declining in North America? So it allows you to look at the drivers of why you're declining and allows you to ask the next level of contextual questions in terms of what can I do differently? So, like a GPS map, it not just tells you where you are, but also allows you to navigate to the right outcomes if you're not going in the right direction. That's the power of the 360 value navigator and the generative AI that simplifies it by making it conversational with data. It's almost like a human interaction where you're just asking the question, you're getting an answer versus making you go through a whole slew of graphs, and lines, and tables, and charts around data. So it makes it very simple, but it is so powerful, given all the foundational AI models that run in the background to be able to provide you those predictive kind of answers that allow you to make better decisions on a day‑to‑day basis. ‑Working with gen AI is redefining the ways we work with our clients, and our services, and within our corporate functions. Next, understanding the key client investments essential for Gen AI reinvention with Sen.

5 Must-do's to lead in Gen AI
The more we learn about gen AI, the more we understand the scale of gen AI, the vast amount of data they need and the computing power required to train and run them, and all that scale requires big investment. But what are the key investments to make for gen AI‑driven reinvention and success? Back to Sen. ‑Gen AI is more human‑like technology than any other technologies that we've seen in the past. If 2023 was the year of experimentation, 2024 is the year of realizing value from gen AI. As our clients embark on their gen AI reinvention, there are five key must dos that they need to invest in. These are key to driving success. Let me unpack that for you. Number one is to lead with value. You can apply gen AI across the entire enterprise. Knowing where to apply is a significant first step. It is critical to shift the focus from siloed use cases to prioritizing business capabilities across the entire value chain based on business outcomes. In short, clients need to be value led in every business capability that they need to choose to reinvent with gen AI. Let's take insurance as an example. There are multiple different business capabilities. As you all know, there's underwriting, there's claims, there's distribution. The value potential, automation, and augmentation potential is significant across these capabilities, and that is exactly where we should begin as we reinvent with gen AI. So the first important imperative is to lead with value and move beyond use cases to prioritizing business capabilities across the value chain based on ROI. The second imperative is to understand and develop an AI‑enabled secure digital core. We all know how important data is for AI. Data is the fuel for AI. Value from gen AI can be extracted from trustworthy and quality data. At the same time, gen AI can enable and accelerate building modern data platforms. We call this the circular data pathway. Clients have choices today on large language models. There are many of them, open source, closed ones, as well as one from hyperscalers. So building a model‑neutral architecture is going to be critical for clients as they embark on this journey. What does it really mean? It means an ability to choose the right models for the right business context. And that is exactly why in Accenture, we built the switchboard architecture. The switchboard architecture will enable our clients to make choices about the right models based on the business context, the cost, accuracy, latency needs, as well as sustainability as well. Leveraging our switchboard will enable our clients to make the right choices for the models at the right time based on these considerations. And the third must do is about talent and ways of working. First, organizations need to completely refresh their talent strategies. Second, it's important to build operating models for new ways of working. Organizations have a once‑in‑a‑lifetime opportunity now to completely reinvent their operating models based on data and based on gen AI. This leads to cultural changes for sure, and that's an important component. It's key to cultivate a corporate culture that places talent development at the forefront. It's also important to consider emerging roles and skills and commit to continuous learning and skilling to maximize the potential of AI, especially because of the changes that have happened with this technology on a weekly basis that we all see now. Focusing on the right talent and skills associated with these new ways of working is foundational. The fourth must do is to close the gap on responsible AI. It's critical to develop and integrate a strategy for responsible AI that brings intentional actions to design, deploy, and use AI to drive value while protecting from the risks of AI. This includes the strategy and development of responsible AI, monitoring and compliance, as well as employing AI security into their entire value chain. The fifth and the final must do is to drive continuous reinvention. This is about embracing a modular step‑by‑step approach to innovation that spans multiple years. It's also about cultivating a corporate culture that views continuous reinvention, not just as a strategy, but as a core competency. These gen AI‑led reinvention journeys are multiyear in nature. They are complex. Companies need to be prepared to allocate capital, time, and talent for the journey. These five must dos interconnect and reinforce each other. I would urge and encourage all of you to follow these five steps as you help your clients reinvent with gen AI. ‑Thank you so much, Sen. Amazing insights to the key investments, both financial and cultural, essential to realize value from gen AI. And there's another powerful force to consider when implementing an LLM, partnerships. That's where we're going next.

The power of partners
The more we learn about gen AI, the more we understand why it's such a game changer and not a light investment. Going it alone on gen AI is something only the very largest global companies can consider because gen AI needs the right technical infrastructure, architecture, operating model, governance structure, cost control, and responsibility by design, which can be too much to manage alone. As I've just demonstrated. In previous tech innovations, the technology itself was relatively stable when it was introduced and the world caught up, but with generative AI, everything is in a state of rapid evolution all at once which makes it even harder to keep up. Luckily, there are all other companies out there that can help keep all these balls up in the air. Here, in Accenture, we call these companies our ecosystem partners. We've asked our global generative AI and ecosystem lead, Denise Zheng, to take us through the different types of ecosystem partners we work with. ‑Things are moving so fast with generative AI that for businesses to keep up the right network of partners, the right ecosystem is critical. We think of the AI ecosystem players in five key segments. The first are application providers. Application providers are the fastest way into gen AI. Off‑the‑shelf products, such as Microsoft 365 Copilot and Salesforce Einstein embed gen AI into business applications that we use every single day. So for example, sales leads and service agents could have AI advisors working alongside them in real time to better engage with customers and prospects. Second are foundation model builders. Foundation model builders provide the building blocks of gen AI. These are language, image, video generation models with a huge focus on driving innovation for AI in consumer and enterprise domains alike. Our partners like OpenAI, Anthropic, Cohere, SambaNova, Scale AI, and NVIDIA are doing some really, really exciting work in this area. Third are the data and platform providers. These partners provide tools to store, manage, and make data accessible and usable at scale on the cloud, and these are also companies helping enterprises ready their data for advanced AI, machine learning, and the digital core. Fourth are the cloud and infrastructure providers. These partners provide the hardware and software bones of any gen AI project. The key partners here are Microsoft, Google, and AWS, and they can also be called hyperscaler innovators as they are constantly driving innovation investment up and down the entire stack. And our final ecosystem partners are found in number five, academic institutions. Now these institutions don't just supply the necessary talent, they help us keep ahead of this fast moving space, and we have partnered with leading institutions like Stanford, MIT, and Oxford to access cutting edge knowledge and talent. ‑Thanks Denise. In such an ever‑evolving world, having the right network of partners will be key to keeping all balls in the air and navigating the rapid change. Unfortunately, no amount of ecosystem partners can teach me to juggle, but you get the idea. Next. Let's learn more about our own internal gen AI tools.

Accenture's internal Gen AI tools
Okay, time to meet our very own proprietary gen AI tools. And where better to explore how we're using AI than in our New York office? Over to you, Brianna. ‑Welcome to New York. The first of our gen AI tools I want you to get to know is Amethyst. Amethyst is Accenture's gen AI‑fueled personal assistant. It generates responses as you explore ideas. It helps you brainstorm creatively, all in real time. Sounds like quite the collaborator. Let's hear a few words from some of our people around the world on Amethyst. ‑I have pinned Amethyst in Teams because for me, I use Teams all day long. So if I want to look up information really quickly and I don't want to go to the Accenture portal, then I just type my query. So for example, recently I needed to contact tech support. So I entered in the question, what is the tech support number? And Amethyst not only gave me the information, it gave me the phone number, but it also gave me some relevant information like the link to the tech support portal page and other useful relevant links. So, I love Amethyst because I don't have to go and navigate somewhere else or open up another browser. I'm always in Teams anyway, so I can just directly ask my questions in Teams. ‑So I had a question about learning and I wanted to know who approves my learning. So I went to Teams and I clicked on the Amethyst icon, and I just typed in the chat, who is my learning approver? And you know, it was very nice because the chatbot answered me, and I had a quick answer. So, it was time‑saving. And I think it's really nice this way because sometimes you have to open a ticket and write to the support and you don't know what to write. So it was a nice interaction, and I had my answer in one second. ‑So Amethyst really helped us in order to prepare for a presentation on generative AI at a retail event. What it helped us with is on two different axis. On the one hand, it really helped us with the content of the presentation and the preparation of the slides. So what we use it for is to look through our knowledge exchange within Accenture and really find the content on Accenture collaboration with AWS and on generative AI, those three to really help us create the right slides and the right content for the event. On the other hand, Amethyst is also able to look through our global network within the organization of Accenture to find the right content that you need in order to answer any questions that you have. We have a lot of knowledge inside our organization and a lot of people in our organization. Amethyst and Teams really helps make them available to any question that you might have. ‑I have used Amethyst and Teams to let generative AI write and generate code for a specific Python programming language. For instance, we can write Ask GPT, followed by a user query, write a Python function to convert a data frame to HTML content. Take an example, data frame having five records. And yes, we get to the result. I mean, it's fascinating to note how we can simply use natural language to generate the code snippet. ‑Fabulous stuff! And if you want to have a go, it's easy. It's here in your Teams toolbar. I've pinned it as chat for easy access. Amethyst can look up your PTO balance for you, check your chargeability, answer tech support questions or even find a client story related to a specific topic. Amethyst can even answer general requests using internet data if you start your query with ask GPT. It's sort of like ChatGPT, but no information ever leaves Accenture's system, which is great. And if you want to know what else it can do, just ask it. You'll find our next gen AI embedded in Accenture search. Type your search as normal, then click the Amethyst icon next to the result to interact. Now, let's hear from some more people. ‑So what's really great was I actually used enterprise search, and some documents that came back ‑ I wanted to learn a little bit more. I clicked the Amethyst icon, and it summarized the content for me. So awesome! ‑And when you want to make it to the very top at Accenture, you'll love our final gen AI tool, our Workday feedback coach. Hi, Emily. You're part of HR. Can you tell me a little bit more about how the coach works? ‑Yes. Giving feedback is so important, as it helps us all to learn and grow. The Workday feedback coach takes your key points and chosen tone and generates feedback on your behalf. ‑Wow, look at it go! That's fast and pretty good already, but is it ready for you to edit straightaway? ‑Yes. As with all generative AI, the role of human oversight can't be overlooked. You must check and edit. ‑Absolutely, especially with something as personal as performance feedback, but it's so much easier to hone what the coach generates than by starting to stare at one of these. Try it yourself, and you'll find the Feedback Hub under Performance in your Workday profile. These are just a few of the amazing gen AI tools that we're creating here and around the world. Working with gen AI tools like this can and will change the way we work. We'll not just be more productive, we'll be more proactive. And if you'd like to see how, go visit go.accenture.com/genaitools. And now, back to the studio. ‑Fantastic! Thanks, Brianna, and all our people across the world who contributed. Gen AI is exciting, but no matter how keen you are to explore our tools, first watch our final section, the Accenture must‑do list for ethical, responsible, and sustainable AI use.

Policies & guidelines
‑TQ isn't just about understanding GenAI, it's about knowing how to use it equitably, sustainably, and without bias. We have people all over the world being more productive and proactive using GenAI ethically, and Brianna's been finding out how they do it. ‑Welcome back to New York. Today, we're talking about Generative AI and all the amazing things that it can do; however, there are still some important considerations. Let's connect with our colleagues and learn more about best practices and things to keep in mind. ‑This is Generative AI, so, it makes things up; fact check everything. Remember, any AI is only as good as the data it was trained on. Biased human decisions and historical and social inequities may influence the results. ‑Thanks, and remember, if you're working on a project that uses Generative AI technology, whether that's procured or provided by Accenture, make sure it has the appropriate approvals. Let's go ahead and check in with our teammates and learn more about what they're doing. ‑It is critical we have human oversight of AI‑generated content and Gen AI products and solutions. If you are using external GenAI tools, you could be accidentally sharing confidential information. Instead, use our own tools such as Amethyst X GPT functionality or the M365 Copilot to keep data secure within the central system. ‑When using AI‑generated content, always acknowledge it by including a disclaimer. ‑Thanks everyone. Another thing to keep in mind is sustainability. Oh, I was about to talk about sustainability, but do you want to take it over for me? ‑Sure, Brianna. Developing training and using GenAI can use a tremendous amount of energy and create a significant carbon footprint. Whether using Generative AI tools yourself or developing a GenAI strategy for your clients, understand the steps you can take to mitigate the environmental impact. ‑Thanks, Bo. And remember, you'll find all of our policies relating to the use of GenAI in the Generative AI Legal playbook or by asking the Center for Advanced AI. Well, that's it from New York. Back to you, Ronnie. ‑GenAI will change the way we work. It's up to us to use it correctly and share that knowledge like we share our TQ. ‑Be sure to check out the exercise files section of this course to download the hands‑on activity on the responsible use of GenAI. ‑With anything new, the more we practice, the better we understand it, so keep practicing, this will prepare you for when your client starts working with GenAI. ‑Thanks for watching TQ TV. We hope we've given you an extra insight into how we're working with GenAI, here, in Accenture.

Gen AI key takeaways
I hope you enjoyed learning more about generative AI. It really is the wave of the future, and I can't emphasize enough how significant it is and how important it is for all of you to be on top of what's happening. As you heard from our experts, generative AI is the latest in a series of technological innovations that have the potential to impact businesses at their core. It will completely transform the way we work and run our businesses. It's exciting that enterprises can tackle problems with a new set of solutions, creating amazing new opportunities for the way we work and live. And generative AI is going to enable new opportunities to increase the human capabilities that we, as people, have. Now before you go, three things. First, be sure to check out the exercise files for this course. I hope you'll give them a try. They're designed to help you put into practice what you've learned, become familiar with Accenture's internal AI tools, and boost your AI skills. Second, join the TQ Viva Engage community. It's the place to be to keep up to date about TQ, and you can participate in our challenges and campaigns. And third, check out our internal generative AI tools, Amethyst, the AI feedback coach in Workday, and the enterprise search function, and more that's coming along. So until next time, keep applying what you learned in TQ and keep learning because generative AI will keep on changing fast, and it is our future.

Bonus content
Gen AI Client Story - Sen Raman
Let me share a client story that highlights the importance of this new data architecture at its best. In fact, it's of my client. My client is a Southeast Asian national oil company that keeps huge volumes of data in different formats and generates more daily. With no efficient way to access and search its data, decision making was only getting slower while the risk of accidents due to missing data points kept growing. Staying on top of pipeline maintenance and repairs was time‑consuming as technicians and engineers had to comb through pages and pages of historical documents to predict where issues may come from. After taking a holistic look at the issues, the company deployed generative AI and cognitive search capability and now can realize the true value of its data and drive new growth. In fact, its new knowledge base incorporates over 250,000 documents with structured and unstructured information, surfaces whatever information the user is looking for, and converts it into a desired format. On the front end, a new search engine simplifies and accelerates the way people find information, allowing them to chat with the company's data to find what they need quickly and in a very conversational manner, speeding up decision making and giving the people the confidence to act. The speed at which the right information can be accessed is also helping avoid equipment downtime as historical data can be accessed almost instantly like finding out how long has it been since a piece of equipment was serviced or had a fault. It is also speeding up onboarding by replacing dense log blocks with a simple search engine to teach complex knowledge. Ultimately, the new integrated setup makes information discoverable with minimal effort, automates the knowledge gathering process for different roles across the organization, and helps reduce accidents.

Gen AI client story - Petra Jantzer
Let me give you one example of recent client work. A group of Accenture leaders recently helped to deliver a 3‑hour generative AI primer at a top leadership summit for one of our largest clients. The meeting included every VP and above of this organization, division president, country managing directors, and regional leads. Together, we educated all of their top leaders about generative AI basics. The team's success actually came not from building a complex AI system, but rather from focusing on education and upskilling around Gen AI. This company aspires to become the world's best IT organization, but they really needed help understanding generative AI basics, so we stepped in to provide that help. The head of AI at this client subsequently approached us with an idea for an intensive AI boot camp. The goal was to train their top architects on how to build generative AI, create applications, and train models within a six‑week period. Despite the very ambitious timeframe, the Accenture team successfully delivered this boot camp. We literally had to go from having no curriculum, no trainers, instructors, anything to putting on a live two‑week boot camp in a six‑week period of time. It wasn't perfect, but it was highly successful. This bootcamp led to the creation of a five‑track learning program for this company with an ambition to deeply skill 10,000 associates to be generative AI developers and leaders over the next 12 months. Because we invested in the content creation for this work, we now own the curriculum and all the content. We have everything from a two‑week intensive boot camp to a 3‑hour executive session and everything in between. This investment has led to a sizable book of business for Accenture in the upcoming year, providing training and learning services to upskill this client's entire organization. Imagine the impact and the reach we have with this type of work.

TQ Takeaway - Emily King
Hi, I'm Emily, and this is my TQ Takeaway over takeaway. Generative AI is something that I hear about every day, but it's not a tool I actively use. The TQ module taught me what makes it different than a search engine. I was planning an upcoming trip, and I was suffering from some major decision fatigue. I turned to generative AI through the form of ChatGPT. I was able to get within seconds a curated list that all fit my Emily‑specific criteria. I had my aha moment, and it finally clicked what it meant to be a prompt engineer and how Gen AI really could be useful in my day‑to‑day life. I feel much more prepared to do as I took the TQ training. So go check it out and see what resonates most for you.

TQ Takeaway - Ross Genovese
Hey, Ross here with my TQ Takeaway and my bag of takeaway. What I love about TQ is that you learn not only about the technology, but also how Accenture is using it and bringing it to clients and how Accenture is leading adoption by laying out the five imperatives to reinventing a business through Gen AI, leading with value, developing a secure AI‑enabled digital core, reinventing talent, closing the gap on a responsible AI, and continually driving reinvention. So make sure you check it out. But first, my burger is getting cold.

TQ Takeaway - Bo Bonero
I'm Bo. I'm going to share with you my TQ Takeaway over takeaway. So my takeaway from TQ was about generative AI. All these little things that affect us I didn't know were happening. How it really makes things simple here at Accenture, an example is our emails. A combination of AI tools that goes through thousands of emails a day takes meetings, and newsletters, and emails, and emails, and emails and then put them together and then customizes it for you. I get my own email, you get your own email. You know what I'm talking about. It's Good Morning Accenture, but what I didn't know was how it worked. And so every morning when you get your Good Morning Accenture, it was Gen AI. I figured that out for you. Well, I'm going to eat this very messy sandwich, and I hope you take your training and get yourself some takeaway as well.

TQ Takeaway - Bas De Vries
Hey, everybody. Good morning. Bas here with TQ Takeaway over a takeaway coffee while my car is charging. One great takeaway from TQ for me personally is the Amethyst tool. While definitely not perfect yet, it is still learning and one great example of how we utilize Gen AI for our everyday lives within Accenture, looking up people in the KX, booking a room, seeing availability within the offices. For these daily purposes, Gen AI can really be supporting. In my personal life, I get a lot of questions about it. But TQ provides us with the basics to get the conversation going. So I would definitely advise you to take the TQ on Gen AI. Good luck.

What are our leaders saying about TQ?
Paul Daugherty
Do you TQ? Generative AI has been changing fast, so you're going to want a TQ to catch up with the latest advances and new insights coming in our latest TQ module.

Sen Ramani
TQ has never been as important or as relevant as it is today. In fact, in this era of Gen AI where we see the velocity with which this technology is moving with breakneck speed is amazing. I encourage all of you to grow your TQ today.

Paolo Dal Cin
TQ has never been so important. It's the learning foundation to help our client in their Gen AI journeys. Security is the strategic enabler that can really fast track the Gen AI adoption in our client. Please do the TQ as soon as possible. Do it tomorrow.

Petra Jantzer
TQ has never been more important than now. Generative AI has the power to transform healthcare and life sciences in so many ways from improving disease diagnosis to accelerating research and expediting drug development. To unlock this value for our clients and bring about changes that will improve the well‑being of society at large, everyone, literally everyone needs to be conversant in Gen AI. So, grow your TQ today.

Andrew Levy
TQ has never been more important. Governments and policymakers around the world are eager to understand the potential of Gen AI and how we can help them. The TQ Gen AI module is essential, therefore, to be able to have well informed and insightful conversations and to establish us as trusted partners and thought leaders. So please be sure to do your TQ training.

Louise Preedy
Hi there. With the pace in which the legal landscape around Gen AI is changing, we all need to keep track with these recent developments. TQ is the way to keep up with technology, but also with the legal side of using it responsibly. So go and grow your TQ today.

Arnab Chakraborty
TQ has never been more important than now. Responsible AI is going to be more important than ever before for AI leaders to create value while building trust and mitigating the risks. So go and grow your TQ.