{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8246b47c",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Jupyter Help</summary>\n",
    "    \n",
    "Having trouble testing your work? Double-check that you have followed the steps below to write, run, save, and test your code!\n",
    "    \n",
    "[Click here for a walkthrough GIF of the steps below](https://static-assets.codecademy.com/Courses/ds-python/jupyter-help.gif)\n",
    "\n",
    "Run all initial cells to import libraries and datasets. Then follow these steps for each question:\n",
    "    \n",
    "1. Add your solution to the cell with `## YOUR SOLUTION HERE ## `.\n",
    "2. Run the cell by selecting the `Run` button or the `Shift`+`Enter` keys.\n",
    "3. Save your work by selecting the `Save` button, the `command`+`s` keys (Mac), or `control`+`s` keys (Windows).\n",
    "4. Select the `Test Work` button at the bottom left to test your work.\n",
    "\n",
    "![Screenshot of the buttons at the top of a Jupyter Notebook. The Run and Save buttons are highlighted](https://static-assets.codecademy.com/Paths/ds-python/jupyter-buttons.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae023367",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9378e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from pprint import pprint\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be577a32",
   "metadata": {},
   "source": [
    "To spare our Codecademy computers a little extra work, we've cut the IMDB dataset down to a smaller CSV file, which we'll import via pandas. If you'd like to see the Hugging Face card for the whole Dataset, check it out [here](https://huggingface.co/datasets/imdb).\n",
    "\n",
    "Execute the next four code cells to import the data and explore it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0fc407",
   "metadata": {},
   "source": [
    "### Imports and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81527792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('imdb_data.csv')\n",
    "print(df.head())\n",
    "print(\"Number of null values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3022245",
   "metadata": {},
   "source": [
    "As you can see, it's pretty simple: the `text` column holds the reviews themselves, while `label` is 1 or 0 (1 is positive sentiment, 0 is negative sentiment.) Finally, the `dataset` column separates the data into training and test sets. There are no null values in the dataset--thanks, Hugging Face!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7904d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataframe Info:\")\n",
    "print(df.info())\n",
    "print(\"\\n\")\n",
    "print(\"Dataframe Description:\")\n",
    "print(df.describe())\n",
    "print(\"\\n\")\n",
    "print(\"Number of unique values in each column:\")\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d692263e",
   "metadata": {},
   "source": [
    "We've got 2500 rows. Let's take a look at a random review to get a feel for how they sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b091284",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = random.randint(0, len(df) - 1)\n",
    "pprint(df.loc[random_index, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curious how this tokenization code works? We'll cover it in more detail at the end of this exercise.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") # this tokenizer will work for our smaller model\n",
    "tokenized_reviews = df['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "review_token_lengths = tokenized_reviews.apply(len)\n",
    "print(f\"Shortest review length (in tokens): {review_token_lengths.min()}\")\n",
    "print(f\"Longest review length (in tokens): {review_token_lengths.max()}\")\n",
    "print(f\"Average review length (in tokens): {review_token_lengths.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39acbdc",
   "metadata": {},
   "source": [
    "Note the warning in the last cell's output above. Some of the examples in the dataset are longer than our model can intake. We'll need to be careful about how we handle the longer reviews in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a945950",
   "metadata": {},
   "source": [
    "### Evaluating the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab94a658",
   "metadata": {},
   "source": [
    "#### Checkpoint 1/3\n",
    "\n",
    "Now that we've explored our data, let's evaluate the base model's performance with test data. This way, we'll have a basic idea of how much better our finetuned model is at classifying the sentiment of movie reviews relative to the model it was based on.\n",
    "\n",
    "Hugging Face's Dataset library has a helpful method, `from_pandas`, that can convert a DataFrame into a Hugging Face Dataset.\n",
    "\n",
    "Call the `from_pandas` method of `Dataset` below, passing in our DataFrame (`df`) as the argument.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318baec",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp1"
    ]
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "dataset=Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a172e5e",
   "metadata": {},
   "source": [
    "#### Checkpoint 2/3\n",
    "\n",
    "Next we'll tokenize the data.\n",
    "\n",
    "Hugging Face provides a useful `.map` method to instantiated datasets. Just pass it a function that takes in the data you want tokenized and outputs the tokenized data.\n",
    "\n",
    "We've defined the `tokenize_function` for you. At the bottom of the cell, use our `dataset`'s `.map()` method to tokenize the data. You'll do this by passing the `tokenize_function` as the first argument, and passing `batched=True` as the second argument so that we'll tokenize the text in batches.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ed471",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp2"
    ]
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"longest\", truncation=True)\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "tokenized_dataset= dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f8289",
   "metadata": {},
   "source": [
    "Good. We'll now instantiate our model, a tiny version of BERT that will be great for learning the basics of writing finetuning code. Execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50740a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d481799",
   "metadata": {},
   "source": [
    "#### Checkpoint 3/3\n",
    "\n",
    "While our warning correctly reminds us that bert-tiny is not ready for production use and should instead first be finetuned, we're going to evaluate it anyway by passing it our test data.\n",
    "\n",
    "That way, we'll have a basic idea of whether or not our finetuning run actually improves the model's ability to classify movie reviews.\n",
    "\n",
    "If you see some unfamiliar code in the cell below, don't worry. We'll cover everything in greater detail soon. For now, tell the model it's in 'evaluation mode' (and not 'training mode') by passing the arguments `do_train=False` and `do_eval=True` to the `TrainingArguments()` call.\n",
    "\n",
    "Then, on the line where we define `eval_results`, run `trainer.evaluate()`. This will print `eval_results` to the console on the next line.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf801b",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp3"
    ]
   },
   "outputs": [],
   "source": [
    "# this is a Hugging Face method that makes it easy to filter our dataset for only 'test' data\n",
    "eval_dataset = tokenized_dataset.filter(lambda x: x['dataset'] == 'test')\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./temp_results',  \n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c3657",
   "metadata": {},
   "source": [
    "Consider writing down the `eval_loss` number, as we'll be comparing it to the finetuned models later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
