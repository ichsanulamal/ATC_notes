{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8246b47c",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Jupyter Help</summary>\n",
    "    \n",
    "Having trouble testing your work? Double-check that you have followed the steps below to write, run, save, and test your code!\n",
    "    \n",
    "[Click here for a walkthrough GIF of the steps below](https://static-assets.codecademy.com/Courses/ds-python/jupyter-help.gif)\n",
    "\n",
    "Run all initial cells to import libraries and datasets. Then follow these steps for each question:\n",
    "    \n",
    "1. Add your solution to the cell with `## YOUR SOLUTION HERE ## `.\n",
    "2. Run the cell by selecting the `Run` button or the `Shift`+`Enter` keys.\n",
    "3. Save your work by selecting the `Save` button, the `command`+`s` keys (Mac), or `control`+`s` keys (Windows).\n",
    "4. Select the `Test Work` button at the bottom left to test your work.\n",
    "\n",
    "![Screenshot of the buttons at the top of a Jupyter Notebook. The Run and Save buttons are highlighted](https://static-assets.codecademy.com/Paths/ds-python/jupyter-buttons.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae023367",
   "metadata": {},
   "source": [
    "**Setup**\n",
    "\n",
    "Run the following cell to import the libraries we'll use and tell the logger to be quiet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9378e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, logging\n",
    "import time\n",
    "\n",
    "logging.set_verbosity_error() # this just clears our cell output of some clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e0e0c",
   "metadata": {},
   "source": [
    "#### Checkpoint 1/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c74d0",
   "metadata": {},
   "source": [
    "Be sure to execute the setup cell before proceeding.\n",
    "\n",
    "We'll first use the `torch.cuda` module to learn more about the GPUs we have available.\n",
    "\n",
    "- you can find out whether or not a GPU is available with `torch.cuda.is_available()`\n",
    "- you can find out *how many* GPUs are available with `torch.cuda.device_count()`\n",
    "- you can find out what the name of the GPUs are, given they exist, with `torch.cuda.get_device_name()`\n",
    "\n",
    "Fill in the three vars below using these three methods then execute the cell. Don't alter any of the other lines or add any other code to the cell.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318baec",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp1"
    ]
   },
   "outputs": [],
   "source": [
    "## YOUR SOLUTION HERE ##\n",
    "is_gpu_available = torch.cuda.is_available()\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "num_of_devices = torch.cuda.device_count()\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name()\n",
    "\n",
    "print(\"Is CUDA available? \", is_gpu_available)\n",
    "print(\"Number of CUDA devices: \", num_of_devices)\n",
    "print(\"CUDA device name: \", device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a172e5e",
   "metadata": {},
   "source": [
    "#### Checkpoint 2/3\n",
    "\n",
    "One very common pattern you'll see in machine learning code is encapsulated in the following line:\n",
    "\n",
    "```python\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "```\n",
    "It finds out whether or not we have a GPU available and, if so, assigns it to `device`. Otherwise, `device` is passed `\"cpu\"`. This pattern enables what's called \"device-agnostic code,\" meaning the code itself doesn't know whether or not we've got GPU access, but will work in either case.\n",
    "\n",
    "Datasets and models are moved to our `device` using the `.to()` method. For instance, to initialize a 3x3 PyTorch tensor with random weights and then assign it to the GPU, we'd write\n",
    "\n",
    "```python\n",
    "tensor = torch.rand(3,3).to(device)\n",
    "```\n",
    "Moving a model to the GPU is the same method. For model `ML_model`, you'd simply write `ML_model.to(device)` (assuming we've defined `device` the way we did above.)\n",
    "\n",
    "Using this information, fill out the cell below.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ed471",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp2"
    ]
   },
   "outputs": [],
   "source": [
    "# device should be 'cuda' if GPU is available, else cpu\n",
    "## YOUR SOLUTION HERE ##\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "# move this tensor to the available device\n",
    "tensor = torch.rand(2, 2).to(device)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=2)\n",
    "## YOUR SOLUTION HERE ##\n",
    "model.to(device)\n",
    "\n",
    "print(\"Device: \", device)\n",
    "print(\"Tensor: \", tensor)\n",
    "print(\"Model device: \", model.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d481799",
   "metadata": {},
   "source": [
    "#### Checkpoint 3/3\n",
    "\n",
    "Notice how the model's device is returned as `\"cuda:0\"`? That's because it's indexed as the *first* GPU in what might be an array of many GPUs. We only have one GPU we'll use, but in larger scale training runs, you might find additional GPUs assigned to `\"cuda:1\"`, `\"cuda:2\"`, and so on.\n",
    "\n",
    "Finally, let's perform a small experiment to see how much the GPU speeds up our computation.\n",
    "\n",
    "First, assign to the variable `cpu_tensor` a randomly-initialized PyTorch tensor with 1,000 rows and 1,000 columns. You can do so with `torch.rand(num_rows, num_columns)`. We'll then add all the values together using the `.sum()` method.\n",
    "\n",
    "Then, under the `torch.cuda.is_available()` if check, assign to the variable `gpu_tensor` another randomized 1,000 x 1,000 tensor, but pass `device=device` as the third argument.\n",
    "\n",
    "Execute the code cell to see how much faster the GPU can sum every number in a 1,000 by 1,000 tensor than the CPU.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details.\n",
    "\n",
    "*Note: The first time you run this cell, the GPU might lag slightly in booting up. If this happens, execute the cell a second time and you will see the speed-up that GPUs typically afford.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf801b",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp3"
    ]
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "## YOUR SOLUTION HERE ##\n",
    "cpu_tensor = torch.rand(1000, 1000)\n",
    "cpu_sum = cpu_tensor.sum()\n",
    "cpu_time = time.time() - start_time\n",
    "print(\"CPU time: \", cpu_time)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    start_time = time.time()\n",
    "## YOUR SOLUTION HERE ##\n",
    "    gpu_tensor = torch.rand(1000, 1000, device=device)\n",
    "    gpu_sum = gpu_tensor.sum()\n",
    "    gpu_time = time.time() - start_time\n",
    "    print(\"GPU time: \", gpu_time)\n",
    "    print(\"Speedup: \", cpu_time / gpu_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
