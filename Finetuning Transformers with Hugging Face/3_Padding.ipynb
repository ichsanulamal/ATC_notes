{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8246b47c",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Jupyter Help</summary>\n",
    "    \n",
    "Having trouble testing your work? Double-check that you have followed the steps below to write, run, save, and test your code!\n",
    "    \n",
    "[Click here for a walkthrough GIF of the steps below](https://static-assets.codecademy.com/Courses/ds-python/jupyter-help.gif)\n",
    "\n",
    "Run all initial cells to import libraries and datasets. Then follow these steps for each question:\n",
    "    \n",
    "1. Add your solution to the cell with `## YOUR SOLUTION HERE ## `.\n",
    "2. Run the cell by selecting the `Run` button or the `Shift`+`Enter` keys.\n",
    "3. Save your work by selecting the `Save` button, the `command`+`s` keys (Mac), or `control`+`s` keys (Windows).\n",
    "4. Select the `Test Work` button at the bottom left to test your work.\n",
    "\n",
    "![Screenshot of the buttons at the top of a Jupyter Notebook. The Run and Save buttons are highlighted](https://static-assets.codecademy.com/Paths/ds-python/jupyter-buttons.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae023367",
   "metadata": {},
   "source": [
    "**Setup**\n",
    "\n",
    "Run this cell to import our tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9378e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e0e0c",
   "metadata": {},
   "source": [
    "#### Checkpoint 1/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c74d0",
   "metadata": {},
   "source": [
    "Be sure to run the setup cell before proceeding.\n",
    "\n",
    "Fixed length padding is desirable when there are strict memory constraints in the system you're using. It's also ideal when consistent input size is necessary for the model's performance.\n",
    "\n",
    "No matter how long the reviews below are, they'll be padded to the `max_length`. \n",
    "\n",
    "Below, tokenize each text in `example_texts` with the tokenizer. Pass as arguments to the tokenizer the `text`, the `padding` argument set to `\"max_length\"`, and the `max_length` argument set to `50`.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318baec",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp1"
    ]
   },
   "outputs": [],
   "source": [
    "example_texts = [\"I am a short sentence.\", \"I am a medium sentence. Not too long, not too short.\", \"I am an exceedingly longwinded, verbose, talks-a-lot, redundant sentence that can't stop running on and on and on.\"]\n",
    "\n",
    "fixed_length_tokens = []\n",
    "for text in example_texts:\n",
    "## YOUR SOLUTION HERE ##\n",
    "    tokenized_text = tokenizer(text, padding=\"max_length\", max_length=50)\n",
    "    fixed_length_tokens.append(tokenized_text)\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"Original text: {example_texts[i]}\")\n",
    "    print(f\"Tokenized text: {fixed_length_tokens[i]['input_ids']}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a172e5e",
   "metadata": {},
   "source": [
    "#### Checkpoint 2/3\n",
    "\n",
    "As you can see, every sequence is padded out to the length specified (in this case, 50 tokens). This is inefficient, because even the longest sequence now contains numerous tokens that aren't teaching the model anything.\n",
    "\n",
    "Dynamic padding, which is what we'll use to pad our training data (and is also the default behavior for AutoTokenizer), addresses this inefficiency. In dynamic padding, each example in the batch is padded out to the length of the longest sequence in the batch.\n",
    "\n",
    "This technique is preferable when there are many differently-lengthed inputs (common in NLP). Try it out by once again passing `tokenizer()` the `example _texts`, but this time also passing the `padding` argument set to `'longest'`.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ed471",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp2"
    ]
   },
   "outputs": [],
   "source": [
    "## YOUR SOLUTION HERE ##\n",
    "dynamically_padded = tokenizer(example_texts, padding=\"longest\")\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"Original text: {example_texts[i]}\")\n",
    "    print(f\"Tokenized text: {dynamically_padded['input_ids'][i]}\")\n",
    "    print(f\"Length of tokenized text: {len(dynamically_padded['input_ids'][i])}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d481799",
   "metadata": {},
   "source": [
    "#### Checkpoint 3/3\n",
    "See how the longwinded sentence contains no padding? That's because every other example only pads out to its length.\n",
    "\n",
    "We've covered how to lengthen examples that are too short. What about the opposite problem?\n",
    "\n",
    "*Truncation* is the technique used to cut off sequences which we decide are too long. The default truncation setting when `True` is to truncate to the longest length permitted by the model. However, you can also set a max length to truncate to, if that is ever a requirement.\n",
    "\n",
    "In the version of `example_texts` below, we now make the long sentence 50 times longer, to a total length of 1402 tokens.\n",
    "\n",
    "First, assign to `tokenized_no_truncation` the tokenized version of `example_texts` with truncation turned off (`truncation=False`).\n",
    "\n",
    "Then, for `tokenized_default_truncation`, simply pass `truncation=True` when passing `example_texts` to the tokenizer.\n",
    "\n",
    "Finally, in `tokenized_max_length`, pass `truncation=True` and `max_length=5` to the tokenizer. Then execute the cell and compare the lengths of each output.\n",
    "\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf801b",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp3"
    ]
   },
   "outputs": [],
   "source": [
    "example_texts = [\"I am a short sentence.\", \"I am an exceedingly longwinded, verbose, talks-a-lot, redundant sentence that can't stop running on.\" * 50]\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "tokenized_no_truncation = tokenizer(example_texts, truncation=False)\n",
    "print(\"Length of non-truncated tokens:\")\n",
    "for idx, tok in enumerate(tokenized_no_truncation['input_ids']):\n",
    "    print(f\"Text {idx+1}: {len(tok)}\")\n",
    "\n",
    "# This automatically truncates to the longest length permitted by the model\n",
    "# (512 for DistilBERT)\n",
    "## YOUR SOLUTION HERE ##\n",
    "tokenized_default_truncation = tokenizer(example_texts, truncation=True)\n",
    "print(\"Length of default truncated tokens:\")\n",
    "for idx, tok in enumerate(tokenized_default_truncation['input_ids']):\n",
    "    print(f\"Text {idx+1}: {len(tok)}\")\n",
    "\n",
    "# Tokenize with truncation (max_length=5)\n",
    "## YOUR SOLUTION HERE ##\n",
    "tokenized_max_length = tokenizer(example_texts, truncation=True, max_length=5)\n",
    "print(\"Length of truncated tokens when max_length = 5:\")\n",
    "for idx, tok in enumerate(tokenized_max_length['input_ids']):\n",
    "    print(f\"Text {idx+1}: {len(tok)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
